{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc77fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e402426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLinUnit(torch.nn.Module):\n",
    "    def __init__(self, dimIn, dim, dW, dW2, dropout=0.):\n",
    "        super(BiLinUnit, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(dimIn, 2 * dim, (2 * dW + 1, 2 * dW + 1), padding=dW, bias=False)\n",
    "        self.conv2 = torch.nn.Conv2d(2 * dim, dim, (2 * dW2 + 1, 2 * dW2 + 1), padding=dW2, bias=False)\n",
    "        self.conv3 = torch.nn.Conv2d(2 * dim, dimIn, (2 * dW2 + 1, 2 * dW2 + 1), padding=dW2, bias=False)\n",
    "        self.bilin0 = torch.nn.Conv2d(dim, dim, (2 * dW2 + 1, 2 * dW2 + 1), padding=dW2, bias=False)\n",
    "        self.bilin1 = torch.nn.Conv2d(dim, dim, (2 * dW2 + 1, 2 * dW2 + 1), padding=dW2, bias=False)\n",
    "        self.bilin2 = torch.nn.Conv2d(dim, dim, (2 * dW2 + 1, 2 * dW2 + 1), padding=dW2, bias=False)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = self.conv1(xin)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(F.relu(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat((self.bilin0(x), self.bilin1(x) * self.bilin2(x)), dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, dimInp, dimAE, dW, dW2, sS, nbBlocks, rateDropout=0.):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.NbBlocks = nbBlocks\n",
    "        self.DimAE = dimAE\n",
    "        # self.conv1HR  = torch.nn.Conv2d(dimInp,self.DimAE,(2*dW+1,2*dW+1),padding=dW,bias=False)\n",
    "        # self.conv1LR  = torch.nn.Conv2d(dimInp,self.DimAE,(2*dW+1,2*dW+1),padding=dW,bias=False)\n",
    "        #self.pool1 = torch.nn.AvgPool2d(sS)\n",
    "        self.pool1 = torch.nn.AvgPool2d((1,sS))\n",
    "        #self.convTr = torch.nn.ConvTranspose2d(dimInp, dimInp, (sS, sS), stride=(sS, sS), bias=False)\n",
    "        self.convTr = torch.nn.ConvTranspose2d(dimInp, dimInp, (1, sS), stride=(1, sS), bias=False)\n",
    "        \n",
    "        # self.NNtLR    = self.__make_ResNet(self.DimAE,self.NbBlocks,rateDropout)\n",
    "        # self.NNHR     = self.__make_ResNet(self.DimAE,self.NbBlocks,rateDropout)\n",
    "        self.NNLR = self.__make_BilinNN(dimInp, self.DimAE, dW, dW2, self.NbBlocks, rateDropout)\n",
    "        self.NNHR = self.__make_BilinNN(dimInp, self.DimAE, dW, dW2, self.NbBlocks, rateDropout)\n",
    "        self.dropout = torch.nn.Dropout(rateDropout)\n",
    "\n",
    "    def __make_BilinNN(self, dimInp, dimAE, dW, dW2, Nb_Blocks=2, dropout=0.):\n",
    "        layers = []\n",
    "        layers.append(BiLinUnit(dimInp, dimAE, dW, dW2, dropout))\n",
    "        for kk in range(0, Nb_Blocks - 1):\n",
    "            layers.append(BiLinUnit(dimAE, dimAE, dW, dW2, dropout))\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, xinp):\n",
    "        ## LR component\n",
    "        xLR = self.NNLR(self.pool1(xinp))\n",
    "        xLR = self.dropout(xLR)\n",
    "        xLR = self.convTr(xLR)\n",
    "        # HR component\n",
    "        xHR = self.NNHR(xinp)\n",
    "        return xLR + xHR\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.mul(1., x)\n",
    "\n",
    "\n",
    "class CorrelateNoise(torch.nn.Module):\n",
    "    def __init__(self, shape_data, dim_cn):\n",
    "        super(CorrelateNoise, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(shape_data, dim_cn, (3, 3), padding=1, bias=False)\n",
    "        self.conv2 = torch.nn.Conv2d(dim_cn, 2 * dim_cn, (3, 3), padding=1, bias=False)\n",
    "        self.conv3 = torch.nn.Conv2d(2 * dim_cn, shape_data, (3, 3), padding=1, bias=False)\n",
    "\n",
    "    def forward(self, w):\n",
    "        w = self.conv1(F.relu(w)).to(device)\n",
    "        w = self.conv2(F.relu(w)).to(device)\n",
    "        w = self.conv3(w).to(device)\n",
    "        return w\n",
    "\n",
    "\n",
    "class RegularizeVariance(torch.nn.Module):\n",
    "    def __init__(self, shape_data, dim_rv):\n",
    "        super(RegularizeVariance, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(shape_data, dim_rv, (3, 3), padding=1, bias=False)\n",
    "        self.conv2 = torch.nn.Conv2d(dim_rv, 2 * dim_rv, (3, 3), padding=1, bias=False)\n",
    "        self.conv3 = torch.nn.Conv2d(2 * dim_rv, shape_data, (3, 3), padding=1, bias=False)\n",
    "\n",
    "    def forward(self, v):\n",
    "        v = self.conv1(F.relu(v)).to(device)\n",
    "        v = self.conv2(F.relu(v)).to(device)\n",
    "        v = self.conv3(v).to(device)\n",
    "        return v\n",
    "\n",
    "class Phi_r(torch.nn.Module):\n",
    "    def __init__(self, shapeData, DimAE, dW, dW2, sS, nbBlocks, rateDr, stochastic=False):\n",
    "        super(Phi_r, self).__init__()\n",
    "        self.encoder = Encoder(shapeData, DimAE, dW, dW2, sS, nbBlocks, rateDr)\n",
    "        self.decoder = Decoder()\n",
    "        self.correlate_noise = CorrelateNoise(shapeData, 10)\n",
    "        self.regularize_variance = RegularizeVariance(shapeData, 10)\n",
    "        self.stochastic = stochastic\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        if self.stochastic == True:\n",
    "            W = torch.randn(x.shape).to(device)\n",
    "            #  g(W) = alpha(x)*h(W)\n",
    "            gW = torch.mul(self.regularize_variance(x),self.correlate_noise(W))\n",
    "            # variance\n",
    "            gW = gW/torch.std(gW)\n",
    "            # print(stats.describe(gW.detach().cpu().numpy()))\n",
    "            x = x + gW\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9966cbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi_r(\n",
       "  (encoder): Encoder(\n",
       "    (pool1): AvgPool2d(kernel_size=(1, 5), stride=(1, 5), padding=0)\n",
       "    (convTr): ConvTranspose2d(1, 1, kernel_size=(1, 5), stride=(1, 5), bias=False)\n",
       "    (NNLR): Sequential(\n",
       "      (0): BiLinUnit(\n",
       "        (conv1): Conv2d(1, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 1, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (1): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (2): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (3): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (4): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (5): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (NNHR): Sequential(\n",
       "      (0): BiLinUnit(\n",
       "        (conv1): Conv2d(1, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 1, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (1): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (2): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (3): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (4): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (5): BiLinUnit(\n",
       "        (conv1): Conv2d(2, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (conv2): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (conv3): Conv2d(4, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin0): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin1): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (bilin2): Conv2d(2, 2, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), bias=False)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder()\n",
       "  (correlate_noise): CorrelateNoise(\n",
       "    (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv3): Conv2d(20, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (regularize_variance): RegularizeVariance(\n",
       "    (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv3): Conv2d(20, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi_r(1,2,3,4,5,6,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03fbe1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CovarianceNetwork(torch.nn.Module):\n",
    "    def __init__(self, shapeData, dimout, dimH):\n",
    "        super(CovarianceNetwork,self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(shapeData, dimH)\n",
    "        self.layer2 = torch.nn.Linear(dimH, dimout)\n",
    "\n",
    "    def forward(self, w):\n",
    "        w = self.layer1(F.relu(w))\n",
    "        w = self.layer2(F.relu(w))\n",
    "        w = torch(w*w)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8adc4b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (<ipython-input-3-876e573f8aac>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-876e573f8aac>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    C()=CovarianceNetwork(2,6,4)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "C=CovarianceNetwork(2,6,4)\n",
    "print(C.layer1.weight)\n",
    "x = torch.rand(20,4,2)\n",
    "print(x.shape)\n",
    "print(C(x))\n",
    "print(C(x).shape)\n",
    "print(device(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aac6f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ Data extraction\n",
      "........ Random seed set to 100\n",
      "[2220.  1020.   764.   744.   577.   535.   511.   329.   279.   218.\n",
      "   92.3   45.  1240.   257.   250.   116.    81.5   46.7   35.3  179.\n",
      "  130.   123.    96.5   78.6   69.    62.1   47.6   81.8   74.4  449.\n",
      "  427. ]\n",
      "(874, 13, 31)\n",
      "(874, 13, 31)\n",
      "... Data type: _ObsSubRnd_50_20\n",
      "(31,)\n",
      "(31, 1)\n",
      "(31, 1)\n",
      "seuil normalisé\n",
      "[[1.31824764]\n",
      " [1.26866338]\n",
      " [1.25838101]\n",
      " [1.25653513]\n",
      " [1.21610044]\n",
      " [1.20150933]\n",
      " [1.2163678 ]\n",
      " [1.19586817]\n",
      " [1.22944378]\n",
      " [1.24693638]\n",
      " [1.17121264]\n",
      " [1.26490812]\n",
      " [1.30504977]\n",
      " [1.24744332]\n",
      " [1.32544306]\n",
      " [1.09160007]\n",
      " [1.1116852 ]\n",
      " [0.87639607]\n",
      " [0.76977733]\n",
      " [1.07203351]\n",
      " [1.04262843]\n",
      " [1.14722608]\n",
      " [1.15214541]\n",
      " [1.14882606]\n",
      " [1.05608624]\n",
      " [1.03135639]\n",
      " [1.07488227]\n",
      " [1.21720527]\n",
      " [1.19016786]\n",
      " [1.21929718]\n",
      " [1.25150911]]\n",
      "..... Training dataset: 13478x31x13\n",
      "..... Validation dataset: 874x31x13\n",
      "..... Test dataset    : 874x31x13\n",
      "........ Initialize interpolated states\n",
      "..... Training dataset: 13478x31x12\n",
      "..... Validation dataset: 874x31x12\n",
      "..... Test dataset    : 874x31x12\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 18 17:59:23 2020\n",
    "@author: rfablet\n",
    "\"\"\"\n",
    "\n",
    "#######################################\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "#import os\n",
    "#import tensorflow.keras as keras\n",
    "import xarray as xr\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.feature_extraction import image\n",
    "from netCDF4 import Dataset\n",
    "import datetime\n",
    "\n",
    "# specific torch module \n",
    "#import dinAE_solver_torch as dinAE\n",
    "#import torch4DVarNN_solver as NN_4DVar\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from netCDF4 import Dataset\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "flagProcess    = [0,1,2,3,4]#Sequence fo processes to be run\n",
    "    \n",
    "flagRandomSeed = 0\n",
    "flagSaveModel  = 1\n",
    "     \n",
    "batch_size  = 256#4#4#8#12#8#256#8 originellement 96\n",
    "\n",
    "dirSAVE     = './ResDanube4DVar/'\n",
    "suffix_exp='exp3'\n",
    "genFilename = 'Debit_v11'\n",
    "  \n",
    "flagAEType = 2 # 0: L96 model, 1-2: GENN\n",
    "DimAE      = 50#50#10#50\n",
    "    \n",
    "UsePriodicBoundary = True # use a periodic boundary for all conv operators in the gradient model (see torch_4DVarNN_dinAE)\n",
    "InterpFlag         = False\n",
    "\n",
    "NbDays          = 18244\n",
    "\n",
    "time_step  = 1\n",
    "DT = 13\n",
    "sigNoise   = np.sqrt(2)\n",
    "rateMissingData = 0.5#0.9\n",
    "width_med_filt_spatial = 5\n",
    "width_med_filt_temp = 1\n",
    "\n",
    "\n",
    "# loss weghing wrt time\n",
    "w_ = np.zeros(DT)\n",
    "w_[int(DT / 2)] = 1.\n",
    "wLoss = torch.Tensor(w_)\n",
    "\n",
    "flagTypeMissData = 4\n",
    "print('........ Data extraction')\n",
    "if flagRandomSeed == 0:\n",
    "    print('........ Random seed set to 100')\n",
    "    np.random.seed(100)\n",
    "        \n",
    "###############################################################\n",
    "## data extraction\n",
    "ncfile = Dataset('Dataset_danube_Copy1.nc',\"r\")\n",
    "L=[]\n",
    "for i in range(31):\n",
    "    L.append(ncfile['S'+str(i+1)][:].reshape(18244,1))\n",
    "        \n",
    "dataset = np.concatenate((L[0],L[1],L[2],L[3],L[4],L[5],L[6],L[7],L[8],L[9],L[10],L[11],L[12],L[13],L[14],L[15],L[16],L[17],L[18],L[19],L[20],L[21],L[22],L[23],L[24],L[25],L[26],L[27],L[28],L[29],L[30]),axis=1)\n",
    "\n",
    "seuil_10 = np.zeros(31)\n",
    "#for i in range(31) :\n",
    "#    Si = sorted(L[i],reverse = True)[int(18244/10)]\n",
    "#    print(Si)\n",
    "#    seuil_10[i]=Si[0]\n",
    "seuil_10 =np.array([2220.,  1020. ,  764.,   744. ,  577. ,  535.,   511.,   329.,   279. ,  218.,\n",
    "   92.3 ,  45.,  1240.,   257. ,  250.,   116. ,   81.5,   46.7,   35.3,  179.,\n",
    "  130.,   123.,    96.5,   78.6 ,  69.,    62.1,   47.6 ,  81.8,   74.4 , 449.,\n",
    "  427. ])    \n",
    "print(seuil_10)\n",
    "\n",
    "\n",
    "# Definiton of training, validation and test dataset    \n",
    "i=0\n",
    "Indtrain=[]\n",
    "Indval=[]\n",
    "Indtest=[]\n",
    "while (i+1)*395<(NbDays-1):\n",
    "    x=395*i\n",
    "    Indtrain.append([x,(x+305)])\n",
    "    Indval.append([(x+319),(x+350)])\n",
    "    Indtest.append([x+364,x+395])\n",
    "    i+=1\n",
    "    \n",
    "\n",
    "#Se restreindre à l'été car pas de pluie??\n",
    "day0=datetime.date(1960,1,1)\n",
    "dayend=datetime.date(2009,12,12)\n",
    "\n",
    "\n",
    "#Trouver une valeur de seuil pour étudier le coût KL au-dessus du seuil : on se place dans flagTypeProcess 3 avec la station 4 masquée\n",
    "\n",
    "D=dataset[Indtrain[0][0]:Indtrain[0][1],3]\n",
    "for k in Indtrain[1::]:\n",
    "    D=np.concatenate((D,dataset[k[0]:k[1],3]),axis=0)\n",
    "r=0.1 #fraction supérieure \n",
    "D.sort()\n",
    "seuil=D[int((1-r)*len(D))]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ####################################################\n",
    "## Generation of training  validationand test dataset\n",
    "## Extraction of time series of dT time steps\n",
    "#NbTraining = 6000#2000\n",
    "#NbTest     = 256#256#500\n",
    "#NbVal = ?\n",
    "    \n",
    "dataTrainingNoNaND = image.extract_patches_2d(dataset[Indtrain[0][0]:Indtrain[0][1],:],(DT,31)) \n",
    "for k in Indtrain[1::]:\n",
    "    d= image.extract_patches_2d(dataset[k[0]:k[1],:],(DT,31))\n",
    "    dataTrainingNoNaND=np.concatenate((dataTrainingNoNaND,d),axis=0)\n",
    "        \n",
    "    \n",
    "dataValNoNaND = image.extract_patches_2d(dataset[Indval[0][0]:Indval[0][1],:],(DT,31))    \n",
    "for k in Indval[1::]:\n",
    "    d= image.extract_patches_2d(dataset[k[0]:k[1],:],(DT,31))\n",
    "    dataValNoNaND=np.concatenate((dataValNoNaND,d),axis=0)\n",
    "print(dataValNoNaND.shape )  \n",
    "    \n",
    "dataTestNoNaND = image.extract_patches_2d(dataset[Indtest[0][0]:Indtest[0][1],:],(DT,31))\n",
    "for k in Indtest[1::]:\n",
    "    d= image.extract_patches_2d(dataset[k[0]:k[1],:],(DT,31))\n",
    "    dataTestNoNaND=np.concatenate((dataTestNoNaND,d),axis=0)\n",
    "print(dataTestNoNaND.shape ) \n",
    "        \n",
    "# create missing data\n",
    "#flagTypeMissData = 0 : Missing data randomly chosen on the patch driven by rateMissingData\n",
    "#flagTypeMissData = 1 : Almost the same\n",
    "#flagTypeMissData = 2 : In each patch, different station are randomly chosen and are masked according to rateMissingData\n",
    "#flagTypeMissData = 3 : The same stations listed in MaskedStations are masked\n",
    "#flagTpeMissData = 4  : Prevision\n",
    "\n",
    "if flagTypeMissData == 0:\n",
    "    indRandD         = np.random.permutation(dataTrainingNoNaND.shape[0]*dataTrainingNoNaND.shape[1]*dataTrainingNoNaND.shape[2])\n",
    "    indRandD         = indRandD[0:int(rateMissingData*len(indRandD))]\n",
    "    dataTrainingD    = np.copy(dataTrainingNoNaND).reshape((dataTrainingNoNaND.shape[0]*dataTrainingNoNaND.shape[1]*dataTrainingNoNaND.shape[2],1))\n",
    "    dataTrainingD[indRandD] = float('nan')\n",
    "    dataTrainingD    = np.reshape(dataTrainingD,(dataTrainingNoNaND.shape[0],dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]))\n",
    "            \n",
    "    indRandD         = np.random.permutation(dataValNoNaND.shape[0]*dataValNoNaND.shape[1]*dataValNoNaND.shape[2])\n",
    "    indRandD         = indRandD[0:int(rateMissingData*len(indRandD))]\n",
    "    dataValD    = np.copy(dataValNoNaND).reshape((dataValNoNaND.shape[0]*dataValNoNaND.shape[1]*dataValNoNaND.shape[2],1))\n",
    "    dataValD[indRandD] = float('nan')\n",
    "    dataValD    = np.reshape(dataValD,(dataValNoNaND.shape[0],dataValNoNaND.shape[1],dataValNoNaND.shape[2]))\n",
    "            \n",
    "            \n",
    "    indRandD         = np.random.permutation(dataTestNoNaND.shape[0]*dataTestNoNaND.shape[1]*dataTestNoNaND.shape[2])\n",
    "    indRandD         = indRandD[0:int(rateMissingData*len(indRandD))]\n",
    "    dataTestD        = np.copy(dataTestNoNaND).reshape((dataTestNoNaND.shape[0]*dataTestNoNaND.shape[1]*dataTestNoNaND.shape[2],1))\n",
    "    dataTestD[indRandD] = float('nan')\n",
    "    dataTestD          = np.reshape(dataTestD,(dataTestNoNaND.shape[0],dataTestNoNaND.shape[1],dataTestNoNaND.shape[2]))\n",
    "\n",
    "    genSuffixObs    = '_ObsRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "        \n",
    "elif flagTypeMissData==1:\n",
    "    time_step_obs   = int(1./(1.-rateMissingData))\n",
    "    dataTrainingD    = np.zeros((dataTrainingNoNaND.shape))\n",
    "    dataTrainingD[:] = float('nan')\n",
    "            \n",
    "    dataValD    = np.zeros((dataValNoNaND.shape))\n",
    "    dataValD[:] = float('nan')\n",
    "            \n",
    "    dataTestD        = np.zeros((dataTestNoNaND.shape))\n",
    "    dataTestD[:]     = float('nan')\n",
    "               \n",
    "    if 1*0:\n",
    "                \n",
    "        dataTrainingD[:,::time_step_obs,:] = dataTrainingNoNaND[:,::time_step_obs,:]\n",
    "        dataValD[:,::time_step_obs,:] = dataValNoNaND[:,::time_step_obs,:]\n",
    "        dataTestD[:,::time_step_obs,:]     = dataTestNoNaND[:,::time_step_obs,:]\n",
    "                    \n",
    "        genSuffixObs    = '_ObsSub_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "    else:\n",
    "        for nn in range(0,dataTrainingD.shape[1],time_step_obs):\n",
    "            indrand = np.random.permutation(dataTrainingD.shape[2])[0:int(0.5*dataTrainingD.shape[1])]\n",
    "            dataTrainingD[:,nn,indrand] = dataTrainingNoNaND[:,nn,indrand]\n",
    "                    \n",
    "        for nn in range(0,dataTrainingD.shape[1],time_step_obs):\n",
    "            indrand = np.random.permutation(dataTrainingD.shape[2])[0:int(0.5*dataTrainingD.shape[1])]\n",
    "            dataValD[:,nn,indrand] = dataValNoNaND[:,nn,indrand]\n",
    "                    \n",
    "        for nn in range(0,dataTrainingD.shape[1],time_step_obs):\n",
    "            indrand = np.random.permutation(dataTrainingD.shape[2])[0:int(0.5*dataTrainingD.shape[1])]\n",
    "            dataTestD[:,nn,indrand] = dataTestNoNaND[:,nn,indrand]\n",
    "\n",
    "        genSuffixObs    = '_ObsSubRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "        \n",
    "elif flagTypeMissData == 2 :\n",
    "    #\n",
    "    Nbtraining=13110\n",
    "    Nbval=506\n",
    "    Nbtest=506\n",
    "            \n",
    "    ratemissingdata_space = 0.15\n",
    "    time_step_obs   = int(1./(1.-rateMissingData))\n",
    "    dataTrainingD    = np.zeros(([Nbtraining,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataTrainingD[:] = float('nan')\n",
    "    dataTrainingNoNaND2    = np.zeros(([Nbtraining,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataTrainingNoNaND2[:] = float('nan')\n",
    "            \n",
    "    dataValD    = np.zeros(([Nbval,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))           \n",
    "    dataValD[:] = float('nan')\n",
    "    dataValNoNaND2=np.zeros(([Nbval,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataValNoNaND2[:] = float('nan')\n",
    "            \n",
    "    dataTestD        = np.zeros(([Nbtest,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataTestD[:]     = float('nan') \n",
    "    dataTestNoNaND2 =np.zeros(([Nbtest,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataTestNoNaND2[:] = float('nan')\n",
    "            \n",
    "    ind=0\n",
    "    print(dataTrainingD.shape)\n",
    "    \n",
    "    while ind<Nbtraining:\n",
    "        indrand=np.random.permutation(dataTrainingD.shape[2])[0:int((1-ratemissingdata_space)*dataTrainingD.shape[2])]\n",
    "        dataTrainingD[ind,:,indrand]=dataTrainingNoNaND[ind%dataTrainingNoNaND.shape[0],:,indrand]\n",
    "        dataTrainingNoNaND2[ind,:,:]=dataTrainingNoNaND[ind%dataTrainingNoNaND.shape[0],:,:]\n",
    "                \n",
    "        if ind <Nbval:\n",
    "            indrand2=np.random.permutation(dataTrainingD.shape[2])[0:int((1-ratemissingdata_space)*dataTrainingD.shape[2])]\n",
    "            dataValD[ind,:,indrand2]=dataValNoNaND[ind%dataValNoNaND.shape[0],:,indrand2]\n",
    "            dataValNoNaND2[ind,:,:]=dataValNoNaND[ind%dataValNoNaND.shape[0],:,:]\n",
    "                \n",
    "            indrand3=np.random.permutation(dataTrainingD.shape[2])[0:int((1-ratemissingdata_space)*dataTrainingD.shape[2])]\n",
    "            dataTestD[ind,:,indrand3]=dataTestNoNaND[ind%dataTestNoNaND.shape[0],:,indrand3]\n",
    "            dataTestNoNaND2[ind,:,:] = dataTestNoNaND[ind%dataTestNoNaND.shape[0],:,:]\n",
    "        ind+=1\n",
    "                \n",
    "    dataTrainingNoNaND =dataTrainingNoNaND2\n",
    "    dataValNoNaND = dataValNoNaND2\n",
    "    dataTestNoNaND =dataTestNoNaND2        \n",
    "    genSuffixObs    = '_ObsSubRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2) \n",
    "        \n",
    "#mask only on specific station\n",
    "elif flagTypeMissData == 3 :\n",
    "    MaskedStations=[2,4,16,25]\n",
    "            \n",
    "    dataTrainingD    = np.zeros((dataTrainingNoNaND.shape))\n",
    "    dataTrainingD[:] = float('nan')\n",
    "            \n",
    "    dataValD    = np.zeros((dataValNoNaND.shape))\n",
    "    dataValD[:] = float('nan')\n",
    "            \n",
    "    dataTestD        = np.zeros((dataTestNoNaND.shape))\n",
    "    dataTestD[:]     = float('nan')\n",
    "    print(dataTrainingNoNaND[0,:,:])  \n",
    "    for i in range(31):\n",
    "        dataTrainingD[:,:,i] = dataTrainingNoNaND[:,:,i]\n",
    "        dataValD[:,:,i] = dataValNoNaND[:,:,i]\n",
    "        dataTestD[:,:,i] = dataTestNoNaND[:,:,i]\n",
    "    for i in MaskedStations:\n",
    "        dataTrainingD[:,:,i-1] = float('nan')\n",
    "        dataValD[:,:,i-1] = float('nan')\n",
    "        dataTestD[:,:,i-1] = float('nan')\n",
    "    genSuffixObs    = '_ObsSubRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "    print(dataTrainingNoNaND[0,:,:])\n",
    "    \n",
    "else : \n",
    "    dataTrainingD    = np.zeros((dataTrainingNoNaND.shape))\n",
    "    dataTrainingD[:] = float('nan')\n",
    "            \n",
    "    dataValD    = np.zeros((dataValNoNaND.shape))\n",
    "    dataValD[:] = float('nan')\n",
    "            \n",
    "    dataTestD        = np.zeros((dataTestNoNaND.shape))\n",
    "    dataTestD[:]     = float('nan')\n",
    "    \n",
    "    dataTrainingD[:,:(int(2*DT/3+1)),:] = dataTrainingNoNaND[:,:(int(2*DT/3+1)),:]\n",
    "    dataValD[:,:(int(2*DT/3+1)),:] = dataValNoNaND[:,:(int(2*DT/3+1)),:]\n",
    "    dataTestD[:,:(int(2*DT/3+1)),:] = dataTestNoNaND[:,:(int(2*DT/3+1)),:]\n",
    "    genSuffixObs    = '_ObsSubRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "    \n",
    "print('... Data type: '+genSuffixObs)\n",
    "    #for nn in range(0,dataTraining.shape[1],time_step_obs):\n",
    "    #    dataTraining[:,::time_step_obs,:] = dataTrainingNoNaN[:,::time_step_obs,:]\n",
    "    #dataTest    = np.zeros((dataTestNoNaN.shape))\n",
    "    #dataTest[:] = float('nan')\n",
    "    #dataTest[:,::time_step_obs,:] = dataTestNoNaN[:,::time_step_obs,:]\n",
    "        \n",
    "# set to NaN patch boundaries    \n",
    "if 1*0:\n",
    "    dataTrainingD[:,0:10,:] =  float('nan')\n",
    "    dataValD[:,0:10,:] =  float('nan')\n",
    "    dataTestD[:,0:10,:]     =  float('nan')\n",
    "    dataTrainingD[:,dT-10:dT,:] =  float('nan')\n",
    "    dataValD[:,dT-10:dT,:] =  float('nan')\n",
    "    dataTestD[:,dT-10:dT,:]     =  float('nan')\n",
    "            \n",
    "                                \n",
    "# mask for NaN\n",
    "maskTrainingD = (dataTrainingD == dataTrainingD).astype('float')\n",
    "maskValD = (dataValD == dataValD).astype('float')\n",
    "maskTestD     = ( dataTestD    ==  dataTestD   ).astype('float')\n",
    "            \n",
    "dataTrainingD = np.nan_to_num(dataTrainingD)\n",
    "        \n",
    "dataValD = np.nan_to_num(dataValD)\n",
    "dataTestD     = np.nan_to_num(dataTestD)\n",
    "            \n",
    "    # Permutation to have channel as #1 component\n",
    "dataTrainingD      = np.moveaxis(dataTrainingD,-1,1)\n",
    "maskTrainingD      = np.moveaxis(maskTrainingD,-1,1)\n",
    "dataTrainingNoNaND = np.moveaxis(dataTrainingNoNaND,-1,1)\n",
    "        \n",
    "dataValD      = np.moveaxis(dataValD,-1,1)\n",
    "maskValD      = np.moveaxis(maskValD,-1,1)\n",
    "dataValNoNaND = np.moveaxis(dataValNoNaND,-1,1)\n",
    "            \n",
    "dataTestD      = np.moveaxis(dataTestD,-1,1)\n",
    "maskTestD      = np.moveaxis(maskTestD,-1,1)\n",
    "dataTestNoNaND = np.moveaxis(dataTestNoNaND,-1,1)\n",
    "            \n",
    "# set to NaN patch boundaries\n",
    "#dataTraining[:,0:5,:] =  dataTrainingNoNaN[:,0:5,:]\n",
    "#dataTest[:,0:5,:]     =  dataTestNoNaN[:,0:5,:]\n",
    "    \n",
    "############################################\n",
    "## raw data\n",
    "X_trainD         = dataTrainingNoNaND\n",
    "        \n",
    "X_train_missingD = dataTrainingD\n",
    "mask_trainD      = maskTrainingD\n",
    "        \n",
    "X_valD         = dataValNoNaND\n",
    "X_val_missingD = dataValD\n",
    "mask_valD      = maskValD\n",
    "        \n",
    "X_testD         = dataTestNoNaND\n",
    "X_test_missingD = dataTestD\n",
    "mask_testD      = maskTestD\n",
    "            \n",
    "############################################\n",
    "## normalized data wrt to each measurement station\n",
    "        \n",
    "if flagTypeMissData ==2 :\n",
    "    mean2 = np.mean(X_train_missingD[:],0)\n",
    "    mean2mask = np.mean(mask_trainD[:],0)\n",
    "\n",
    "\n",
    "    mean3 = np.mean(mean2,1)\n",
    "    mean3 = mean3.reshape(31,1)\n",
    "    print(mean3)\n",
    "    mean3mask = np.mean(mean2mask,1)\n",
    "    mean3mask = mean3mask.reshape(31,1)\n",
    "    print(mean3mask)\n",
    "    meanTr          = mean3/mean3mask\n",
    "    print(meanTr)\n",
    "    mean2true = np.mean(X_trainD[:],0)\n",
    "    mean3true = np.mean(mean2true,1)\n",
    "    mean3true = mean3true.reshape(31,1)\n",
    "    meanTrtrue = mean3true\n",
    "    print(meanTrtrue)\n",
    "            \n",
    "    meansquaretrue = np.mean( (X_trainD-meanTrtrue)**2,0)\n",
    "    meansquare2true = np.mean(meansquaretrue,1)\n",
    "    meansquare2true=meansquare2true.reshape(31,1)\n",
    "    stdTrtrue           = np.sqrt(meansquare2true )\n",
    "    print(stdTrtrue)\n",
    "            \n",
    "            \n",
    "    x_train_missingD = X_train_missingD - meanTr*mask_trainD\n",
    "            \n",
    "    x_val_missingD = X_val_missingD - meanTr*mask_valD\n",
    "    x_test_missingD  = X_test_missingD - meanTr*mask_testD\n",
    "            \n",
    "    # scale wrt to each station\n",
    "    meansquare = np.mean( X_train_missingD**2,0)\n",
    "    meansquare2 = np.mean(meansquare,1)\n",
    "    meansquare2=meansquare2.reshape(31,1)\n",
    "    stdTr           = np.sqrt(meansquare2 / mean3mask)\n",
    "            \n",
    "    x_train_missingD = x_train_missingD / stdTr\n",
    "    x_val_missingD = x_val_missingD / stdTr\n",
    "    x_test_missingD  = x_test_missingD / stdTr\n",
    "            \n",
    "    x_trainD = (X_trainD - meanTr) / stdTr\n",
    "    x_valD = (X_valD - meanTr) / stdTr\n",
    "    x_testD  = (X_testD - meanTr) / stdTr\n",
    "            \n",
    "    print(np.mean(x_train_missingD))\n",
    "    print(np.mean(x_trainD))\n",
    "    print(np.mean(x_val_missingD))\n",
    "    print(np.mean(x_valD))\n",
    "    print(np.mean(x_test_missingD))\n",
    "    print(np.mean(x_testD))\n",
    "            \n",
    "            \n",
    "               \n",
    "elif flagTypeMissData==3 :\n",
    "    mean2 = np.mean(X_train_missingD[:],0)\n",
    "    mean3 = np.mean(mean2,1)\n",
    "    mean3 = mean3.reshape(31,1)\n",
    "    meanTr = mean3\n",
    "    x_train_missingD = X_train_missingD - meanTr\n",
    "    x_val_missingD = X_val_missingD - meanTr\n",
    "    x_test_missingD  = X_test_missingD - meanTr\n",
    "    meansquare = np.mean( x_train_missingD**2,0)\n",
    "    meansquare2 = np.mean(meansquare,1)\n",
    "    meansquare2=meansquare2.reshape(31,1)\n",
    "            \n",
    "    stdTr           = np.sqrt(meansquare2)\n",
    "            \n",
    "    for i in MaskedStations :\n",
    "        stdTr[i-1] =1\n",
    "    print(stdTr)\n",
    "    print(X_trainD[0,:,:])\n",
    "    x_train_missingD = x_train_missingD / stdTr\n",
    "    x_val_missingD = x_val_missingD / stdTr\n",
    "    x_test_missingD  = x_test_missingD / stdTr\n",
    "    mean2true = np.mean(X_trainD[:],0)\n",
    "    mean3true = np.mean(mean2true,1)\n",
    "    mean3true = mean3true.reshape(31,1)\n",
    "    meanTrtrue = mean3true\n",
    "            \n",
    "    meansquaretrue = np.mean( (X_trainD-meanTrtrue)**2,0)\n",
    "    meansquare2true = np.mean(meansquaretrue,1)\n",
    "    meansquare2true=meansquare2true.reshape(31,1)\n",
    "    stdTrtrue           = np.sqrt(meansquare2true )\n",
    "    print(stdTrtrue)\n",
    "    print(meanTrtrue)\n",
    "            \n",
    "    x_trainD = (X_trainD - meanTrtrue) / stdTrtrue\n",
    "    x_valD = (X_valD - meanTrtrue) / stdTrtrue\n",
    "    x_testD  = (X_testD - meanTrtrue) / stdTrtrue\n",
    "            \n",
    "elif flagTypeMissData == 4 :\n",
    "    #Moyenne des débits par station sur l'échatillon total\n",
    "    M = np.mean(X_trainD,0)\n",
    "    mean_X_trainD = np.mean(M,1)\n",
    "    mean_X_trainD = mean_X_trainD.reshape(31,1)\n",
    "    meanTr        = mean_X_trainD\n",
    "    meanTrtrue = meanTr\n",
    "    #Moyenne des débits\n",
    "    X_nomask=X_trainD[:,:,:(int(2*DT/3+1))]\n",
    "    M2 = np.mean(X_nomask,0)\n",
    "    mean_X_train_missingD = np.mean(M2,1)\n",
    "    mean_X_train_missingD = mean_X_train_missingD.reshape(31,1)\n",
    "\n",
    "    #Ecart-type:\n",
    "    meansquaretrue = np.mean( (X_trainD-mean_X_trainD)**2,0)\n",
    "    meansquare2true = np.mean(meansquaretrue,1)\n",
    "    meansquare2true=meansquare2true.reshape(31,1)\n",
    "    stdTrtrue           = np.sqrt(meansquare2true )\n",
    "    \n",
    "    #Normalisation et standardisation des données\n",
    "    x_train_missingD = np.zeros(X_train_missingD.shape)\n",
    "    x_train_missingD[:,:,:(int(2*DT/3)+1)]=(X_train_missingD[:,:,:(int(2*DT/3)+1)]-mean_X_trainD)/stdTrtrue\n",
    " \n",
    "    x_val_missingD = np.zeros(X_val_missingD.shape)\n",
    "    x_val_missingD[:,:,:(int(2*DT/3)+1)]=(X_val_missingD[:,:,:(int(2*DT/3)+1)]-mean_X_trainD)/stdTrtrue\n",
    "\n",
    "    x_test_missingD = np.zeros(X_test_missingD.shape)\n",
    "    x_test_missingD[:,:,:(int(2*DT/3)+1)]=(X_test_missingD[:,:,:(int(2*DT/3)+1)]-mean_X_trainD)/stdTrtrue\n",
    "\n",
    "\n",
    "    x_trainD = (X_trainD - mean_X_trainD) / stdTrtrue\n",
    "    x_valD = (X_valD - mean_X_trainD) / stdTrtrue\n",
    "    x_testD  = (X_testD - mean_X_trainD) / stdTrtrue\n",
    "    \n",
    "    stdTr =stdTrtrue\n",
    "    \n",
    "else : \n",
    "    mean2 = np.mean(X_train_missingD[:],0)\n",
    "    mean2mask = np.mean(mask_trainD[:],0)\n",
    "            \n",
    "\n",
    "    mean3 = np.mean(mean2,1)\n",
    "    mean3 = mean3.reshape(31,1)\n",
    "    print(mean3)\n",
    "    mean3mask = np.mean(mean2mask,1)\n",
    "    mean3mask = mean3mask.reshape(31,1)\n",
    "    print(mean3mask)\n",
    "    meanTr          = mean3/mean3mask\n",
    "    print(meanTr)\n",
    "            \n",
    "    x_train_missingD = X_train_missingD - meanTr*mask_trainD\n",
    "    x_val_missingD = X_val_missingD - meanTr\n",
    "    x_test_missingD  = X_test_missingD - meanTr\n",
    "            \n",
    "    # scale wrt to each station\n",
    "    meansquare = np.mean( X_train_missingD**2,0)\n",
    "    meansquare2 = np.mean(meansquare,1)\n",
    "    meansquare2=meansquare2.reshape(31,1)\n",
    "    stdTr           = np.sqrt(meansquare2 / mean3mask)\n",
    "            \n",
    "    x_train_missingD = x_train_missingD / stdTr\n",
    "    x_val_missingD = x_val_missingD / stdTr\n",
    "    x_test_missingD  = x_test_missingD / stdTr\n",
    "            \n",
    "    x_trainD = (X_trainD - meanTr) / stdTr\n",
    "    x_valD = (X_valD - meanTr) / stdTr\n",
    "    x_testD  = (X_testD - meanTr) / stdTr\n",
    "            \n",
    "# Generate noisy observsation\n",
    "        \n",
    "#X_train_obsD = X_train_missingD + sigNoise * maskTrainingD * np.random.randn(X_train_missingD.shape[0],X_train_missingD.shape[1],X_train_missingD.shape[2])\n",
    "#X_val_obsD = X_val_missingD + sigNoise * maskValD * np.random.randn(X_val_missingD.shape[0],X_val_missingD.shape[1],X_val_missingD.shape[2])\n",
    "#X_test_obsD  = X_test_missingD  + sigNoise * maskTestD * np.random.randn(X_test_missingD.shape[0],X_test_missingD.shape[1],X_test_missingD.shape[2])\n",
    "            \n",
    "#x_train_obsD = (X_train_obsD - meanTr) / stdTr\n",
    "#x_val_obsD = (X_val_obsD - meanTr) / stdTr\n",
    "#x_test_obsD  = (X_test_obsD - meanTr) / stdTr\n",
    "        \n",
    "#Without noise :\n",
    "X_train_obsD = X_train_missingD \n",
    "X_val_obsD = X_val_missingD \n",
    "X_test_obsD  = X_test_missingD\n",
    "        \n",
    "x_train_obsD = x_train_missingD\n",
    "x_val_obsD = x_val_missingD\n",
    "x_test_obsD = x_test_missingD \n",
    "\n",
    "m_seuil = ((seuil_10.reshape(31,1)-meanTr)/stdTr)\n",
    "print(seuil_10.shape)\n",
    "print(meanTr.shape)\n",
    "print(stdTr.shape)\n",
    "print(\"seuil normalisé\")\n",
    "print(m_seuil)\n",
    "        \n",
    "print('..... Training dataset: %dx%dx%d'%(x_train_missingD.shape[0],x_trainD.shape[1],x_trainD.shape[2]))\n",
    "print('..... Validation dataset: %dx%dx%d'%(x_valD.shape[0],x_valD.shape[1],x_valD.shape[2]))\n",
    "print('..... Test dataset    : %dx%dx%d'%(x_testD.shape[0],x_testD.shape[1],x_testD.shape[2]))\n",
    "            \n",
    "\n",
    "print('........ Initialize interpolated states')\n",
    "## Initial interpolation\n",
    "#flagInit = 0 : Masked values are replaced by 0\n",
    "#flagInit = 1 : masked values are replaced by last available value (prevision)\n",
    "#flaginit = 2 : Interpolation \n",
    "\n",
    "flagInit = 1\n",
    "\n",
    "            \n",
    "if flagInit == 0: \n",
    "    X_train_InitD = mask_trainD * X_train_obsD + (1. - mask_trainD) * (np.zeros(X_train_missingD.shape) + meanTr)\n",
    "    X_val_InitD = mask_valD * X_val_obsD + (1. - mask_valD) * (np.zeros(X_val_missingD.shape) + meanTr)\n",
    "    X_test_InitD  = mask_testD * X_test_obsD + (1. - mask_testD) * (np.zeros(X_test_missingD.shape) + meanTr)\n",
    "    \n",
    "elif flagInit==1 :\n",
    "    X_ext_train = X_train_missingD[:,:,int(2*DT/3)].reshape(X_train_missingD.shape[0],X_train_missingD.shape[1],1)\n",
    "    X_train_InitD = mask_trainD * X_train_obsD + (1. - mask_trainD)*X_ext_train\n",
    "    X_ext_val = X_val_missingD[:,:,int(2*DT/3)].reshape(X_val_missingD.shape[0],X_val_missingD.shape[1],1)\n",
    "    X_val_InitD = mask_valD * X_val_obsD + (1. - mask_valD)*X_ext_val\n",
    "    X_ext_test = X_test_missingD[:,:,int(2*DT/3)].reshape(X_test_missingD.shape[0],X_test_missingD.shape[1],1)\n",
    "    X_test_InitD = mask_testD * X_test_obsD + (1. - mask_testD)*X_ext_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "else:\n",
    "    X_train_InitD = np.zeros(X_trainD.shape)\n",
    "    for ii in range(0,X_trainD.shape[0]):\n",
    "        # Initial linear interpolation for each component\n",
    "        XInitD = np.zeros((X_trainD.shape[1],X_trainD.shape[2]))\n",
    "           \n",
    "        for kk in range(0,mask_trainD.shape[1]):\n",
    "            indt  = np.where( mask_trainD[ii,kk,:] == 1.0 )[0]\n",
    "            indt_ = np.where( mask_trainD[ii,kk,:] == 0.0 )[0]\n",
    "           \n",
    "            if len(indt) > 1:\n",
    "                indt_[ np.where( indt_ < np.min(indt)) ] = np.min(indt)\n",
    "                indt_[ np.where( indt_ > np.max(indt)) ] = np.max(indt)\n",
    "                fkk = scipy.interpolate.interp1d(indt, X_train_obsD[ii,kk,indt])\n",
    "                XInitD[kk,indt]  = X_train_obsD[ii,kk,indt]\n",
    "                XInitD[kk,indt_] = fkk(indt_)\n",
    "            else:\n",
    "                XInitD = XInitD + meanTr\n",
    "            \n",
    "        X_train_InitD[ii,:,:] = XInitD\n",
    "            \n",
    "    X_val_InitD = np.zeros(X_valD.shape)\n",
    "    for ii in range(0,X_valD.shape[0]):\n",
    "        # Initial linear interpolation for each component\n",
    "        XInitD = np.zeros((X_valD.shape[1],X_valD.shape[2]))\n",
    "           \n",
    "        for kk in range(0,mask_valD.shape[1]):\n",
    "            indt  = np.where( mask_valD[ii,kk,:] == 1.0 )[0]\n",
    "            indt_ = np.where( mask_valD[ii,kk,:] == 0.0 )[0]\n",
    "           \n",
    "            if len(indt) > 1:\n",
    "                indt_[ np.where( indt_ < np.min(indt)) ] = np.min(indt)\n",
    "                indt_[ np.where( indt_ > np.max(indt)) ] = np.max(indt)\n",
    "                fkk = scipy.interpolate.interp1d(indt, X_val_obsD[ii,kk,indt])\n",
    "                XInitD[kk,indt]  = X_val_obsD[ii,kk,indt]\n",
    "                XInitD[kk,indt_] = fkk(indt_)\n",
    "            else:\n",
    "                XInitD = XInitD + meanTr\n",
    "            \n",
    "        X_val_InitD[ii,:,:] = XInitD\n",
    "            \n",
    "    X_test_InitD = np.zeros(X_testD.shape)\n",
    "    for ii in range(0,X_testD.shape[0]):\n",
    "        # Initial linear interpolation for each component\n",
    "        XInit = np.zeros((X_testD.shape[1],X_testD.shape[2]))\n",
    "            \n",
    "        for kk in range(0,X_testD.shape[1]):\n",
    "            indt  = np.where( mask_testD[ii,kk,:] == 1.0 )[0]\n",
    "            indt_ = np.where( mask_testD[ii,kk,:] == 0.0 )[0]\n",
    "            \n",
    "            if len(indt) > 1:\n",
    "                indt_[ np.where( indt_ < np.min(indt)) ] = np.min(indt)\n",
    "                indt_[ np.where( indt_ > np.max(indt)) ] = np.max(indt)\n",
    "                fkk = scipy.interpolate.interp1d(indt, X_test_obsD[ii,kk,indt])\n",
    "                XInit[kk,indt]  = X_test_obsD[ii,kk,indt]\n",
    "                XInit[kk,indt_] = fkk(indt_)\n",
    "            else:\n",
    "                XInit = XInit + meanTr\n",
    "        \n",
    "        X_test_InitD[ii,:,:] = XInit\n",
    "        #plt.figure()\n",
    "        #plt.figure()\n",
    "        #plt.plot(YObs[0:200,1],'r.')\n",
    "        #plt.plot(XGT[0:200,1],'b-')\n",
    "        #plt.plot(XInit[0:200,1],'k-')\n",
    "                        \n",
    "x_train_InitD = ( X_train_InitD - meanTr ) / stdTr\n",
    "x_val_InitD = ( X_val_InitD - meanTr ) / stdTr\n",
    "x_test_InitD = ( X_test_InitD - meanTr ) / stdTr\n",
    "        \n",
    "# reshape to dT-1 for time dimension\n",
    "DT = DT-1\n",
    "X_train_obsD        = X_train_obsD[:,:,0:DT]\n",
    "X_trainD            = X_trainD[:,:,0:DT]\n",
    "X_train_missingD    = X_train_missingD[:,:,0:DT]\n",
    "mask_trainD         = mask_trainD[:,:,0:DT]\n",
    "            \n",
    "x_train_obsD        = x_train_obsD[:,:,0:DT]\n",
    "x_trainD            = x_trainD[:,:,0:DT]\n",
    "x_train_InitD       = x_train_InitD[:,:,0:DT]\n",
    "X_train_InitD       = X_train_InitD[:,:,0:DT]\n",
    "        \n",
    "X_val_obsD        = X_val_obsD[:,:,0:DT]\n",
    "X_valD            = X_valD[:,:,0:DT]\n",
    "X_val_missingD    = X_val_missingD[:,:,0:DT]\n",
    "mask_valD         = mask_valD[:,:,0:DT]\n",
    "            \n",
    "x_val_obsD        = x_val_obsD[:,:,0:DT]\n",
    "x_valD            = x_valD[:,:,0:DT]\n",
    "x_val_InitD       = x_val_InitD[:,:,0:DT]\n",
    "X_val_InitD       = X_val_InitD[:,:,0:DT]\n",
    "\n",
    "X_test_obsD        = X_test_obsD[:,:,0:DT]\n",
    "X_testD            = X_testD[:,:,0:DT]\n",
    "X_test_missingD    = X_test_missingD[:,:,0:DT]\n",
    "mask_testD         = mask_testD[:,:,0:DT]\n",
    "\n",
    "x_test_obsD        = x_test_obsD[:,:,0:DT]\n",
    "x_testD            = x_testD[:,:,0:DT]\n",
    "x_test_InitD       = x_test_InitD[:,:,0:DT]\n",
    "X_test_InitD       = X_test_InitD[:,:,0:DT]\n",
    "\n",
    "print('..... Training dataset: %dx%dx%d'%(x_trainD.shape[0],x_trainD.shape[1],x_trainD.shape[2]))\n",
    "print('..... Validation dataset: %dx%dx%d'%(x_valD.shape[0],x_valD.shape[1],x_valD.shape[2]))\n",
    "print('..... Test dataset    : %dx%dx%d'%(x_testD.shape[0],x_testD.shape[1],x_testD.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b740b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000430744763107\n",
      "1.047662421960815\n",
      "1.0661778697596147\n",
      "0.12310378896799264\n",
      "0.13217613565121983\n"
     ]
    }
   ],
   "source": [
    "print(var_Tr)\n",
    "print(var_Tt)\n",
    "print(var_Val)\n",
    " \n",
    "print(mean_Tt)\n",
    "print(mean_Val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4df966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..... Training dataset: 13110x31x20\n",
      "..... Validation dataset: 506x31x20\n",
      "..... Test dataset    : 506x31x20\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b92b63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, hparam, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        h= hparam if isinstance(hparam, dict) else OmegaConf.to_container(hparam, resolve=True)\n",
    "        self.save_hyperparameters(h)\n",
    "        \n",
    "        print(self.hparams)\n",
    "        #self.save_hyperparameters(hparams)\n",
    "        self.var_Val = kwargs['var_Val']\n",
    "        self.var_Tr = kwargs['var_Tr']\n",
    "        self.var_Tt = kwargs['var_Tt']\n",
    "\n",
    "        # create longitudes & latitudes coordinates\n",
    "        \n",
    "        print(self.hparams.dT)\n",
    "        self.shapeData = [self.hparams.dT*2,self.hparams.NbStations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86ba35c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-1d23c609e0f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mod = LitModel(hparam = cfg, w_loss= wLoss,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                mean_Tr=meanTrtrue, mean_Tt=mean_Tt, mean_Val=mean_Val,var_Tr=var_Tr,var_Tt=var_Tt,var_Val=var_Val)\n\u001b[1;32m      3\u001b[0m                              \u001b[0;31m#var_Tr, var_Tt, var_Val,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-47756a079b99>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hparam, *args, **kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhparam\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/4dvarnet/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36msave_hyperparameters\u001b[0;34m(self, ignore, frame, *args)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m         \u001b[0msave_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/4dvarnet/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py\u001b[0m in \u001b[0;36msave_hyperparameters\u001b[0;34m(obj, ignore, frame, *args)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misx_non_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misx_non_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mcand_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hparams_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcand_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcand_names\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/4dvarnet/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misx_non_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misx_non_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mcand_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hparams_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcand_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcand_names\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "mod = LitModel(hparam = cfg, w_loss= wLoss,\n",
    "                               mean_Tr=meanTrtrue, mean_Tt=mean_Tt, mean_Val=mean_Val,var_Tr=var_Tr,var_Tt=var_Tt,var_Val=var_Val)\n",
    "                             #var_Tr, var_Tt, var_Val,\n",
    "                               \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5969d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4dvarnet",
   "language": "python",
   "name": "4dvarnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
