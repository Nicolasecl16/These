{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a49c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ Data extraction\n",
      "........ Random seed set to 100\n",
      "[2220.  1020.   764.   744.   577.   535.   511.   329.   279.   218.\n",
      "   92.3   45.  1240.   257.   250.   116.    81.5   46.7   35.3  179.\n",
      "  130.   123.    96.5   78.6   69.    62.1   47.6   81.8   74.4  449.\n",
      "  427. ]\n",
      "(874, 13, 31)\n",
      "(874, 13, 31)\n",
      "... Data type: _ObsSubRnd_50_20\n",
      "(31,)\n",
      "(31, 1)\n",
      "(31, 1)\n",
      "seuil normalisé\n",
      "[[1.31824764]\n",
      " [1.26866338]\n",
      " [1.25838101]\n",
      " [1.25653513]\n",
      " [1.21610044]\n",
      " [1.20150933]\n",
      " [1.2163678 ]\n",
      " [1.19586817]\n",
      " [1.22944378]\n",
      " [1.24693638]\n",
      " [1.17121264]\n",
      " [1.26490812]\n",
      " [1.30504977]\n",
      " [1.24744332]\n",
      " [1.32544306]\n",
      " [1.09160007]\n",
      " [1.1116852 ]\n",
      " [0.87639607]\n",
      " [0.76977733]\n",
      " [1.07203351]\n",
      " [1.04262843]\n",
      " [1.14722608]\n",
      " [1.15214541]\n",
      " [1.14882606]\n",
      " [1.05608624]\n",
      " [1.03135639]\n",
      " [1.07488227]\n",
      " [1.21720527]\n",
      " [1.19016786]\n",
      " [1.21929718]\n",
      " [1.25150911]]\n",
      "..... Training dataset: 13478x31x13\n",
      "..... Validation dataset: 874x31x13\n",
      "..... Test dataset    : 874x31x13\n",
      "........ Initialize interpolated states\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 18 17:59:23 2020\n",
    "@author: rfablet\n",
    "\"\"\"\n",
    "\n",
    "#######################################\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "#import os\n",
    "#import tensorflow.keras as keras\n",
    "import xarray as xr\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.feature_extraction import image\n",
    "from netCDF4 import Dataset\n",
    "import datetime\n",
    "\n",
    "# specific torch module \n",
    "#import dinAE_solver_torch as dinAE\n",
    "import torch_4DVarNN_dinAE_Copy1 as NN_4DVar\n",
    "#import torch4DVarNN_solver as NN_4DVar\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "'''\n",
    "# !/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../4dvarnet-core')\n",
    "import solver as NN_4DVar\n",
    "\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "flagProcess    = [0,1,2,3,4]#Sequence fo processes to be run\n",
    "    \n",
    "flagRandomSeed = 0\n",
    "flagSaveModel  = 1\n",
    "     \n",
    "batch_size  = 96#4#4#8#12#8#256#8 originellement 96\n",
    "\n",
    "dirSAVE     = './ResDanube4DVar/'\n",
    "suffix_exp='exp3'\n",
    "genFilename = 'Debit_v11'\n",
    "  \n",
    "flagAEType = 2 # 0: L96 model, 1-2: GENN\n",
    "DimAE      = 50#50#10#50\n",
    "    \n",
    "UsePriodicBoundary = True # use a periodic boundary for all conv operators in the gradient model (see torch_4DVarNN_dinAE)\n",
    "InterpFlag         = False\n",
    "\n",
    "NbDays          = 18244\n",
    "\n",
    "time_step  = 1\n",
    "DT = 13\n",
    "sigNoise   = np.sqrt(2)\n",
    "rateMissingData = 0.5#0.9\n",
    "width_med_filt_spatial = 5\n",
    "width_med_filt_temp = 1\n",
    "\n",
    "\n",
    "# loss weghing wrt time\n",
    "w_ = np.zeros(DT)\n",
    "w_[int(DT / 2)] = 1.\n",
    "wLoss = torch.Tensor(w_)\n",
    "\n",
    "flagTypeMissData = 4\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "\n",
    "#import torch.distributed as dist\n",
    "\n",
    "## NN architectures and optimization parameters\n",
    "#batch_size      = 2#16#4#4#8#12#8#256#\n",
    "#DimAE           = 50#10#10#50\n",
    "#dimGradSolver   = 100 # dimension of the hidden state of the LSTM cell\n",
    "#rateDropout     = 0.25 # dropout rate \n",
    "#flag_aug_state = 2#True#\n",
    "#flag_augment_training_data = True#False#\n",
    "\n",
    "# data generation\n",
    "#sigNoise = 0. ## additive noise standard deviation\n",
    "#flagSWOTData = True #False # rue ## use SWOT data or not\n",
    "#flagNoSSTObs = False #True #\n",
    "#flag_vv  = 'vv_10m'\n",
    "\n",
    "#width_med_filt_spatial = 5\n",
    "#width_med_filt_temp = 1\n",
    "\n",
    "#dT              = 5 ## Time window of each space-time patch\n",
    "#W               = 200 ## width/height of each space-time patch\n",
    "#dx              = 1 ## subsampling step if > 1\n",
    "#Nbpatches       = 1#10#10#25 ## number of patches extracted from each time-step \n",
    "#rnd1            = 0 ## random seed for patch extraction (space sam)\n",
    "#rnd2            = 100 ## random seed for patch extraction\n",
    "#dwscale         = 1\n",
    "\n",
    "# loss\n",
    "#p_norm_loss = 2. \n",
    "#q_norm_loss = 2. \n",
    "#r_norm_loss = 2. \n",
    "#thr_norm_loss = 0.\n",
    "\n",
    "#W = int(W/dx)\n",
    "\n",
    "#UsePriodicBoundary = False # use a periodic boundary for all conv operators in the gradient model (see torch_4DVarNN_dinAE)\n",
    "#InterpFlag         = False # True => force reconstructed field to observed data after each gradient-based update\n",
    "\n",
    "print('........ Data extraction')\n",
    "if flagRandomSeed == 0:\n",
    "    print('........ Random seed set to 100')\n",
    "    np.random.seed(100)\n",
    "        \n",
    "###############################################################\n",
    "## data extraction\n",
    "ncfile = Dataset('Dataset_danube.nc',\"r\")\n",
    "L=[]\n",
    "for i in range(31):\n",
    "    L.append(ncfile['S'+str(i+1)][:].reshape(18244,1))\n",
    "        \n",
    "dataset = np.concatenate((L[0],L[1],L[2],L[3],L[4],L[5],L[6],L[7],L[8],L[9],L[10],L[11],L[12],L[13],L[14],L[15],L[16],L[17],L[18],L[19],L[20],L[21],L[22],L[23],L[24],L[25],L[26],L[27],L[28],L[29],L[30]),axis=1)\n",
    "\n",
    "seuil_10 = np.zeros(31)\n",
    "#for i in range(31) :\n",
    "#    Si = sorted(L[i],reverse = True)[int(18244/10)]\n",
    "#    print(Si)\n",
    "#    seuil_10[i]=Si[0]\n",
    "seuil_10 =np.array([2220.,  1020. ,  764.,   744. ,  577. ,  535.,   511.,   329.,   279. ,  218.,\n",
    "   92.3 ,  45.,  1240.,   257. ,  250.,   116. ,   81.5,   46.7,   35.3,  179.,\n",
    "  130.,   123.,    96.5,   78.6 ,  69.,    62.1,   47.6 ,  81.8,   74.4 , 449.,\n",
    "  427. ])    \n",
    "print(seuil_10)\n",
    "\n",
    "\n",
    "# Definiton of training, validation and test dataset    \n",
    "i=0\n",
    "Indtrain=[]\n",
    "Indval=[]\n",
    "Indtest=[]\n",
    "while (i+1)*395<(NbDays-1):\n",
    "    x=395*i\n",
    "    Indtrain.append([x,(x+305)])\n",
    "    Indval.append([(x+319),(x+350)])\n",
    "    Indtest.append([x+364,x+395])\n",
    "    i+=1\n",
    "    \n",
    "\n",
    "#Se restreindre à l'été car pas de pluie??\n",
    "day0=datetime.date(1960,1,1)\n",
    "dayend=datetime.date(2009,12,12)\n",
    "\n",
    "\n",
    "#Trouver une valeur de seuil pour étudier le coût KL au-dessus du seuil : on se place dans flagTypeProcess 3 avec la station 4 masquée\n",
    "\n",
    "D=dataset[Indtrain[0][0]:Indtrain[0][1],3]\n",
    "for k in Indtrain[1::]:\n",
    "    D=np.concatenate((D,dataset[k[0]:k[1],3]),axis=0)\n",
    "r=0.1 #fraction supérieure \n",
    "D.sort()\n",
    "seuil=D[int((1-r)*len(D))]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Definiton of training, validation and test dataset\n",
    "# from dayly indices over a one-year time series\n",
    "\n",
    "suffix_exp = \"exp2\"\n",
    "day_0 = datetime.date(2012,10,1)\n",
    "\n",
    "if suffix_exp == \"exp3\" :\n",
    "    iiVal = 60 - int(dT / 2)\n",
    "    jjVal = iiVal + 20 + int(dT / 2) #int(dT / 2)\n",
    "    \n",
    "    iiTest = jjVal + 10 #90 - int(dT / 2)\n",
    "    jjTest = iiTest + 20 + 2*int(dT / 2) # 110 + int(dT / 2)\n",
    "     \n",
    "    iiTr1 = 0\n",
    "    jjTr1 = iiVal - 10 #50 - int(dT / 2)\n",
    "    \n",
    "    iiTr2 = jjTest + 10 #130 + int(dT / 2)\n",
    "    jjTr2 = 365\n",
    "elif suffix_exp == \"exp2\" :\n",
    "    day_val  = datetime.date(2013,1,1)\n",
    "    iiVal = int((day_val - day_0).days)\n",
    "    jjVal = iiVal + 20 + 2*int(dT / 2) #int(dT / 2)\n",
    "    \n",
    "    day_test_0  = datetime.date(2012,10,22)\n",
    "    day_test_1  = datetime.date(2012,12,2)\n",
    "    iiTest = int((day_test_0 - day_0).days) - int(dT / 2) #90 - int(dT / 2)\n",
    "    jjTest = int((day_test_1 - day_0).days) + int(dT / 2) # 110 + int(dT / 2)\n",
    "     \n",
    "    iiTr1 = jjVal + 10\n",
    "    jjTr1 = 365\n",
    "    \n",
    "    iiTr2 = 365 #130 + int(dT / 2)\n",
    "    jjTr2 = 365\n",
    "elif suffix_exp == \"summer\" : # Summer\n",
    "    day_val  = datetime.date(2013,7,1)\n",
    "    iiVal = int((day_val - day_0).days)\n",
    "    jjVal = iiVal + 20 + 2*int(dT / 2) #int(dT / 2)\n",
    "    \n",
    "    iiTest = jjVal + 10 #90 - int(dT / 2)\n",
    "    jjTest = iiTest + 20 + 2*int(dT / 2) # 110 + int(dT / 2)\n",
    "     \n",
    "    iiTr1 = 0\n",
    "    jjTr1 = iiVal - 10 #50 - int(dT / 2)\n",
    "    \n",
    "    iiTr2 = jjTest + 10 #130 + int(dT / 2)\n",
    "    jjTr2 = 365\n",
    "elif suffix_exp == \"spring\" : # Spring\n",
    "    day_val  = datetime.date(2013,4,1)\n",
    "    iiVal = int((day_val - day_0).days)\n",
    "    jjVal = iiVal + 20 + 2*int(dT / 2) #int(dT / 2)\n",
    "    \n",
    "    iiTest = jjVal + 10 #90 - int(dT / 2)\n",
    "    jjTest = iiTest + 20 + 2*int(dT / 2) # 110 + int(dT / 2)\n",
    "     \n",
    "    iiTr1 = 0\n",
    "    jjTr1 = iiVal - 10 #50 - int(dT / 2)\n",
    "    \n",
    "    iiTr2 = jjTest + 10 #130 + int(dT / 2)\n",
    "    jjTr2 = 365\n",
    "elif suffix_exp == \"winter\" : # Winter\n",
    "    day_val  = datetime.date(2013,1,1)\n",
    "    iiVal = int((day_val - day_0).days)\n",
    "    jjVal = iiVal + 20 + 2*int(dT / 2) #int(dT / 2)\n",
    "    \n",
    "    iiTest = jjVal + 10 #90 - int(dT / 2)\n",
    "    jjTest = iiTest + 20 + 2*int(dT / 2) # 110 + int(dT / 2)\n",
    "     \n",
    "    iiTr1 = 0\n",
    "    jjTr1 = iiVal - 10 #50 - int(dT / 2)\n",
    "    \n",
    "    iiTr2 = jjTest + 10 #130 + int(dT / 2)\n",
    "    jjTr2 = 365\n",
    "elif suffix_exp == \"fall\" : # Fall\n",
    "    day_val  = datetime.date(2012,10,1)\n",
    "    iiVal = int((day_val - day_0).days)\n",
    "    jjVal = iiVal + 20 + 2*int(dT / 2) #int(dT / 2)\n",
    "    \n",
    "    iiTest = jjVal + 10 #90 - int(dT / 2)\n",
    "    jjTest = iiTest + 20 + 2*int(dT / 2) # 110 + int(dT / 2)\n",
    "     \n",
    "    iiTr1 = 0\n",
    "    jjTr1 = iiVal - 10 #50 - int(dT / 2)\n",
    "    \n",
    "    iiTr2 = jjTest + 10 #130 + int(dT / 2)\n",
    "    jjTr2 = 365\n",
    "elif suffix_exp == \"winter2\" : # Winter\n",
    "    day_val  = datetime.date(2013,1,1)\n",
    "    iiVal = int((day_val - day_0).days)\n",
    "    jjVal = iiVal + 20 + 2*int(dT / 2) #int(dT / 2)\n",
    "    \n",
    "    iiTest = jjVal + 30 #90 - int(dT / 2)\n",
    "    jjTest = iiTest + 20 + 2*int(dT / 2) # 110 + int(dT / 2)\n",
    "     \n",
    "    iiTr1 = 0\n",
    "    jjTr1 = iiVal - 10 #50 - int(dT / 2)\n",
    "    \n",
    "    iiTr2 = jjTest + 30 #130 + int(dT / 2)\n",
    "    jjTr2 = 365\n",
    "elif suffix_exp == \"spring2\" : # Spring\n",
    "    day_val  = datetime.date(2013,4,1)\n",
    "    iiVal = int((day_val - day_0).days)\n",
    "    jjVal = iiVal + 20 + 2*int(dT / 2) #int(dT / 2)\n",
    "    \n",
    "    iiTest = jjVal + 30 #90 - int(dT / 2)\n",
    "    jjTest = iiTest + 20 + 2*int(dT / 2) # 110 + int(dT / 2)\n",
    "     \n",
    "    iiTr1 = 0\n",
    "    jjTr1 = iiVal - 10 #50 - int(dT / 2)\n",
    "    \n",
    "    iiTr2 = jjTest + 30 #130 + int(dT / 2)\n",
    "    jjTr2 = 365\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    ####################################################\n",
    "## Generation of training  validationand test dataset\n",
    "## Extraction of time series of dT time steps\n",
    "#NbTraining = 6000#2000\n",
    "#NbTest     = 256#256#500\n",
    "#NbVal = ?\n",
    "    \n",
    "dataTrainingNoNaND = image.extract_patches_2d(dataset[Indtrain[0][0]:Indtrain[0][1],:],(DT,31)) \n",
    "for k in Indtrain[1::]:\n",
    "    d= image.extract_patches_2d(dataset[k[0]:k[1],:],(DT,31))\n",
    "    dataTrainingNoNaND=np.concatenate((dataTrainingNoNaND,d),axis=0)\n",
    "        \n",
    "    \n",
    "dataValNoNaND = image.extract_patches_2d(dataset[Indval[0][0]:Indval[0][1],:],(DT,31))    \n",
    "for k in Indval[1::]:\n",
    "    d= image.extract_patches_2d(dataset[k[0]:k[1],:],(DT,31))\n",
    "    dataValNoNaND=np.concatenate((dataValNoNaND,d),axis=0)\n",
    "print(dataValNoNaND.shape )  \n",
    "    \n",
    "dataTestNoNaND = image.extract_patches_2d(dataset[Indtest[0][0]:Indtest[0][1],:],(DT,31))\n",
    "for k in Indtest[1::]:\n",
    "    d= image.extract_patches_2d(dataset[k[0]:k[1],:],(DT,31))\n",
    "    dataTestNoNaND=np.concatenate((dataTestNoNaND,d),axis=0)\n",
    "print(dataTestNoNaND.shape ) \n",
    "        \n",
    "# create missing data\n",
    "#flagTypeMissData = 0 : Missing data randomly chosen on the patch driven by rateMissingData\n",
    "#flagTypeMissData = 1 : Almost the same\n",
    "#flagTypeMissData = 2 : In each patch, different station are randomly chosen and are masked according to rateMissingData\n",
    "#flagTypeMissData = 3 : The same stations listed in MaskedStations are masked\n",
    "#flagTpeMissData = 4  : Prevision\n",
    "\n",
    "if flagTypeMissData == 0:\n",
    "    indRandD         = np.random.permutation(dataTrainingNoNaND.shape[0]*dataTrainingNoNaND.shape[1]*dataTrainingNoNaND.shape[2])\n",
    "    indRandD         = indRandD[0:int(rateMissingData*len(indRandD))]\n",
    "    dataTrainingD    = np.copy(dataTrainingNoNaND).reshape((dataTrainingNoNaND.shape[0]*dataTrainingNoNaND.shape[1]*dataTrainingNoNaND.shape[2],1))\n",
    "    dataTrainingD[indRandD] = float('nan')\n",
    "    dataTrainingD    = np.reshape(dataTrainingD,(dataTrainingNoNaND.shape[0],dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]))\n",
    "            \n",
    "    indRandD         = np.random.permutation(dataValNoNaND.shape[0]*dataValNoNaND.shape[1]*dataValNoNaND.shape[2])\n",
    "    indRandD         = indRandD[0:int(rateMissingData*len(indRandD))]\n",
    "    dataValD    = np.copy(dataValNoNaND).reshape((dataValNoNaND.shape[0]*dataValNoNaND.shape[1]*dataValNoNaND.shape[2],1))\n",
    "    dataValD[indRandD] = float('nan')\n",
    "    dataValD    = np.reshape(dataValD,(dataValNoNaND.shape[0],dataValNoNaND.shape[1],dataValNoNaND.shape[2]))\n",
    "            \n",
    "            \n",
    "    indRandD         = np.random.permutation(dataTestNoNaND.shape[0]*dataTestNoNaND.shape[1]*dataTestNoNaND.shape[2])\n",
    "    indRandD         = indRandD[0:int(rateMissingData*len(indRandD))]\n",
    "    dataTestD        = np.copy(dataTestNoNaND).reshape((dataTestNoNaND.shape[0]*dataTestNoNaND.shape[1]*dataTestNoNaND.shape[2],1))\n",
    "    dataTestD[indRandD] = float('nan')\n",
    "    dataTestD          = np.reshape(dataTestD,(dataTestNoNaND.shape[0],dataTestNoNaND.shape[1],dataTestNoNaND.shape[2]))\n",
    "\n",
    "    genSuffixObs    = '_ObsRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "        \n",
    "elif flagTypeMissData==1:\n",
    "    time_step_obs   = int(1./(1.-rateMissingData))\n",
    "    dataTrainingD    = np.zeros((dataTrainingNoNaND.shape))\n",
    "    dataTrainingD[:] = float('nan')\n",
    "            \n",
    "    dataValD    = np.zeros((dataValNoNaND.shape))\n",
    "    dataValD[:] = float('nan')\n",
    "            \n",
    "    dataTestD        = np.zeros((dataTestNoNaND.shape))\n",
    "    dataTestD[:]     = float('nan')\n",
    "               \n",
    "    if 1*0:\n",
    "                \n",
    "        dataTrainingD[:,::time_step_obs,:] = dataTrainingNoNaND[:,::time_step_obs,:]\n",
    "        dataValD[:,::time_step_obs,:] = dataValNoNaND[:,::time_step_obs,:]\n",
    "        dataTestD[:,::time_step_obs,:]     = dataTestNoNaND[:,::time_step_obs,:]\n",
    "                    \n",
    "        genSuffixObs    = '_ObsSub_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "    else:\n",
    "        for nn in range(0,dataTrainingD.shape[1],time_step_obs):\n",
    "            indrand = np.random.permutation(dataTrainingD.shape[2])[0:int(0.5*dataTrainingD.shape[1])]\n",
    "            dataTrainingD[:,nn,indrand] = dataTrainingNoNaND[:,nn,indrand]\n",
    "                    \n",
    "        for nn in range(0,dataTrainingD.shape[1],time_step_obs):\n",
    "            indrand = np.random.permutation(dataTrainingD.shape[2])[0:int(0.5*dataTrainingD.shape[1])]\n",
    "            dataValD[:,nn,indrand] = dataValNoNaND[:,nn,indrand]\n",
    "                    \n",
    "        for nn in range(0,dataTrainingD.shape[1],time_step_obs):\n",
    "            indrand = np.random.permutation(dataTrainingD.shape[2])[0:int(0.5*dataTrainingD.shape[1])]\n",
    "            dataTestD[:,nn,indrand] = dataTestNoNaND[:,nn,indrand]\n",
    "\n",
    "        genSuffixObs    = '_ObsSubRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "        \n",
    "elif flagTypeMissData == 2 :\n",
    "    #\n",
    "    Nbtraining=13110\n",
    "    Nbval=506\n",
    "    Nbtest=506\n",
    "            \n",
    "    ratemissingdata_space = 0.15\n",
    "    time_step_obs   = int(1./(1.-rateMissingData))\n",
    "    dataTrainingD    = np.zeros(([Nbtraining,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataTrainingD[:] = float('nan')\n",
    "    dataTrainingNoNaND2    = np.zeros(([Nbtraining,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataTrainingNoNaND2[:] = float('nan')\n",
    "            \n",
    "    dataValD    = np.zeros(([Nbval,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))           \n",
    "    dataValD[:] = float('nan')\n",
    "    dataValNoNaND2=np.zeros(([Nbval,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataValNoNaND2[:] = float('nan')\n",
    "            \n",
    "    dataTestD        = np.zeros(([Nbtest,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataTestD[:]     = float('nan') \n",
    "    dataTestNoNaND2 =np.zeros(([Nbtest,dataTrainingNoNaND.shape[1],dataTrainingNoNaND.shape[2]]))\n",
    "    dataTestNoNaND2[:] = float('nan')\n",
    "            \n",
    "    ind=0\n",
    "    print(dataTrainingD.shape)\n",
    "    \n",
    "    while ind<Nbtraining:\n",
    "        indrand=np.random.permutation(dataTrainingD.shape[2])[0:int((1-ratemissingdata_space)*dataTrainingD.shape[2])]\n",
    "        dataTrainingD[ind,:,indrand]=dataTrainingNoNaND[ind%dataTrainingNoNaND.shape[0],:,indrand]\n",
    "        dataTrainingNoNaND2[ind,:,:]=dataTrainingNoNaND[ind%dataTrainingNoNaND.shape[0],:,:]\n",
    "                \n",
    "        if ind <Nbval:\n",
    "            indrand2=np.random.permutation(dataTrainingD.shape[2])[0:int((1-ratemissingdata_space)*dataTrainingD.shape[2])]\n",
    "            dataValD[ind,:,indrand2]=dataValNoNaND[ind%dataValNoNaND.shape[0],:,indrand2]\n",
    "            dataValNoNaND2[ind,:,:]=dataValNoNaND[ind%dataValNoNaND.shape[0],:,:]\n",
    "                \n",
    "            indrand3=np.random.permutation(dataTrainingD.shape[2])[0:int((1-ratemissingdata_space)*dataTrainingD.shape[2])]\n",
    "            dataTestD[ind,:,indrand3]=dataTestNoNaND[ind%dataTestNoNaND.shape[0],:,indrand3]\n",
    "            dataTestNoNaND2[ind,:,:] = dataTestNoNaND[ind%dataTestNoNaND.shape[0],:,:]\n",
    "        ind+=1\n",
    "                \n",
    "    dataTrainingNoNaND =dataTrainingNoNaND2\n",
    "    dataValNoNaND = dataValNoNaND2\n",
    "    dataTestNoNaND =dataTestNoNaND2        \n",
    "    genSuffixObs    = '_ObsSubRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2) \n",
    "        \n",
    "#mask only on specific station\n",
    "elif flagTypeMissData == 3 :\n",
    "    MaskedStations=[2,4,16,25]\n",
    "            \n",
    "    dataTrainingD    = np.zeros((dataTrainingNoNaND.shape))\n",
    "    dataTrainingD[:] = float('nan')\n",
    "            \n",
    "    dataValD    = np.zeros((dataValNoNaND.shape))\n",
    "    dataValD[:] = float('nan')\n",
    "            \n",
    "    dataTestD        = np.zeros((dataTestNoNaND.shape))\n",
    "    dataTestD[:]     = float('nan')\n",
    "    print(dataTrainingNoNaND[0,:,:])  \n",
    "    for i in range(31):\n",
    "        dataTrainingD[:,:,i] = dataTrainingNoNaND[:,:,i]\n",
    "        dataValD[:,:,i] = dataValNoNaND[:,:,i]\n",
    "        dataTestD[:,:,i] = dataTestNoNaND[:,:,i]\n",
    "    for i in MaskedStations:\n",
    "        dataTrainingD[:,:,i-1] = float('nan')\n",
    "        dataValD[:,:,i-1] = float('nan')\n",
    "        dataTestD[:,:,i-1] = float('nan')\n",
    "    genSuffixObs    = '_ObsSubRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "    print(dataTrainingNoNaND[0,:,:])\n",
    "    \n",
    "else : \n",
    "    dataTrainingD    = np.zeros((dataTrainingNoNaND.shape))\n",
    "    dataTrainingD[:] = float('nan')\n",
    "            \n",
    "    dataValD    = np.zeros((dataValNoNaND.shape))\n",
    "    dataValD[:] = float('nan')\n",
    "            \n",
    "    dataTestD        = np.zeros((dataTestNoNaND.shape))\n",
    "    dataTestD[:]     = float('nan')\n",
    "    \n",
    "    dataTrainingD[:,:(int(2*DT/3+1)),:] = dataTrainingNoNaND[:,:(int(2*DT/3+1)),:]\n",
    "    dataValD[:,:(int(2*DT/3+1)),:] = dataValNoNaND[:,:(int(2*DT/3+1)),:]\n",
    "    dataTestD[:,:(int(2*DT/3+1)),:] = dataTestNoNaND[:,:(int(2*DT/3+1)),:]\n",
    "    genSuffixObs    = '_ObsSubRnd_%02d_%02d'%(100*rateMissingData,10*sigNoise**2)\n",
    "    \n",
    "print('... Data type: '+genSuffixObs)\n",
    "    #for nn in range(0,dataTraining.shape[1],time_step_obs):\n",
    "    #    dataTraining[:,::time_step_obs,:] = dataTrainingNoNaN[:,::time_step_obs,:]\n",
    "    #dataTest    = np.zeros((dataTestNoNaN.shape))\n",
    "    #dataTest[:] = float('nan')\n",
    "    #dataTest[:,::time_step_obs,:] = dataTestNoNaN[:,::time_step_obs,:]\n",
    "        \n",
    "# set to NaN patch boundaries    \n",
    "if 1*0:\n",
    "    dataTrainingD[:,0:10,:] =  float('nan')\n",
    "    dataValD[:,0:10,:] =  float('nan')\n",
    "    dataTestD[:,0:10,:]     =  float('nan')\n",
    "    dataTrainingD[:,dT-10:dT,:] =  float('nan')\n",
    "    dataValD[:,dT-10:dT,:] =  float('nan')\n",
    "    dataTestD[:,dT-10:dT,:]     =  float('nan')\n",
    "            \n",
    "                                \n",
    "# mask for NaN\n",
    "maskTrainingD = (dataTrainingD == dataTrainingD).astype('float')\n",
    "maskValD = (dataValD == dataValD).astype('float')\n",
    "maskTestD     = ( dataTestD    ==  dataTestD   ).astype('float')\n",
    "            \n",
    "dataTrainingD = np.nan_to_num(dataTrainingD)\n",
    "        \n",
    "dataValD = np.nan_to_num(dataValD)\n",
    "dataTestD     = np.nan_to_num(dataTestD)\n",
    "            \n",
    "    # Permutation to have channel as #1 component\n",
    "dataTrainingD      = np.moveaxis(dataTrainingD,-1,1)\n",
    "maskTrainingD      = np.moveaxis(maskTrainingD,-1,1)\n",
    "dataTrainingNoNaND = np.moveaxis(dataTrainingNoNaND,-1,1)\n",
    "        \n",
    "dataValD      = np.moveaxis(dataValD,-1,1)\n",
    "maskValD      = np.moveaxis(maskValD,-1,1)\n",
    "dataValNoNaND = np.moveaxis(dataValNoNaND,-1,1)\n",
    "            \n",
    "dataTestD      = np.moveaxis(dataTestD,-1,1)\n",
    "maskTestD      = np.moveaxis(maskTestD,-1,1)\n",
    "dataTestNoNaND = np.moveaxis(dataTestNoNaND,-1,1)\n",
    "            \n",
    "# set to NaN patch boundaries\n",
    "#dataTraining[:,0:5,:] =  dataTrainingNoNaN[:,0:5,:]\n",
    "#dataTest[:,0:5,:]     =  dataTestNoNaN[:,0:5,:]\n",
    "    \n",
    "############################################\n",
    "## raw data\n",
    "X_trainD         = dataTrainingNoNaND\n",
    "        \n",
    "X_train_missingD = dataTrainingD\n",
    "mask_trainD      = maskTrainingD\n",
    "        \n",
    "X_valD         = dataValNoNaND\n",
    "X_val_missingD = dataValD\n",
    "mask_valD      = maskValD\n",
    "        \n",
    "X_testD         = dataTestNoNaND\n",
    "X_test_missingD = dataTestD\n",
    "mask_testD      = maskTestD\n",
    "            \n",
    "############################################\n",
    "## normalized data wrt to each measurement station\n",
    "        \n",
    "if flagTypeMissData ==2 :\n",
    "    mean2 = np.mean(X_train_missingD[:],0)\n",
    "    mean2mask = np.mean(mask_trainD[:],0)\n",
    "\n",
    "\n",
    "    mean3 = np.mean(mean2,1)\n",
    "    mean3 = mean3.reshape(31,1)\n",
    "    print(mean3)\n",
    "    mean3mask = np.mean(mean2mask,1)\n",
    "    mean3mask = mean3mask.reshape(31,1)\n",
    "    print(mean3mask)\n",
    "    meanTr          = mean3/mean3mask\n",
    "    print(meanTr)\n",
    "    mean2true = np.mean(X_trainD[:],0)\n",
    "    mean3true = np.mean(mean2true,1)\n",
    "    mean3true = mean3true.reshape(31,1)\n",
    "    meanTrtrue = mean3true\n",
    "    print(meanTrtrue)\n",
    "            \n",
    "    meansquaretrue = np.mean( (X_trainD-meanTrtrue)**2,0)\n",
    "    meansquare2true = np.mean(meansquaretrue,1)\n",
    "    meansquare2true=meansquare2true.reshape(31,1)\n",
    "    stdTrtrue           = np.sqrt(meansquare2true )\n",
    "    print(stdTrtrue)\n",
    "            \n",
    "            \n",
    "    x_train_missingD = X_train_missingD - meanTr*mask_trainD\n",
    "            \n",
    "    x_val_missingD = X_val_missingD - meanTr*mask_valD\n",
    "    x_test_missingD  = X_test_missingD - meanTr*mask_testD\n",
    "            \n",
    "    # scale wrt to each station\n",
    "    meansquare = np.mean( X_train_missingD**2,0)\n",
    "    meansquare2 = np.mean(meansquare,1)\n",
    "    meansquare2=meansquare2.reshape(31,1)\n",
    "    stdTr           = np.sqrt(meansquare2 / mean3mask)\n",
    "            \n",
    "    x_train_missingD = x_train_missingD / stdTr\n",
    "    x_val_missingD = x_val_missingD / stdTr\n",
    "    x_test_missingD  = x_test_missingD / stdTr\n",
    "            \n",
    "    x_trainD = (X_trainD - meanTr) / stdTr\n",
    "    x_valD = (X_valD - meanTr) / stdTr\n",
    "    x_testD  = (X_testD - meanTr) / stdTr\n",
    "            \n",
    "    print(np.mean(x_train_missingD))\n",
    "    print(np.mean(x_trainD))\n",
    "    print(np.mean(x_val_missingD))\n",
    "    print(np.mean(x_valD))\n",
    "    print(np.mean(x_test_missingD))\n",
    "    print(np.mean(x_testD))\n",
    "            \n",
    "            \n",
    "               \n",
    "elif flagTypeMissData==3 :\n",
    "    mean2 = np.mean(X_train_missingD[:],0)\n",
    "    mean3 = np.mean(mean2,1)\n",
    "    mean3 = mean3.reshape(31,1)\n",
    "    meanTr = mean3\n",
    "    x_train_missingD = X_train_missingD - meanTr\n",
    "    x_val_missingD = X_val_missingD - meanTr\n",
    "    x_test_missingD  = X_test_missingD - meanTr\n",
    "    meansquare = np.mean( x_train_missingD**2,0)\n",
    "    meansquare2 = np.mean(meansquare,1)\n",
    "    meansquare2=meansquare2.reshape(31,1)\n",
    "            \n",
    "    stdTr           = np.sqrt(meansquare2)\n",
    "            \n",
    "    for i in MaskedStations :\n",
    "        stdTr[i-1] =1\n",
    "    print(stdTr)\n",
    "    print(X_trainD[0,:,:])\n",
    "    x_train_missingD = x_train_missingD / stdTr\n",
    "    x_val_missingD = x_val_missingD / stdTr\n",
    "    x_test_missingD  = x_test_missingD / stdTr\n",
    "    mean2true = np.mean(X_trainD[:],0)\n",
    "    mean3true = np.mean(mean2true,1)\n",
    "    mean3true = mean3true.reshape(31,1)\n",
    "    meanTrtrue = mean3true\n",
    "            \n",
    "    meansquaretrue = np.mean( (X_trainD-meanTrtrue)**2,0)\n",
    "    meansquare2true = np.mean(meansquaretrue,1)\n",
    "    meansquare2true=meansquare2true.reshape(31,1)\n",
    "    stdTrtrue           = np.sqrt(meansquare2true )\n",
    "    print(stdTrtrue)\n",
    "    print(meanTrtrue)\n",
    "            \n",
    "    x_trainD = (X_trainD - meanTrtrue) / stdTrtrue\n",
    "    x_valD = (X_valD - meanTrtrue) / stdTrtrue\n",
    "    x_testD  = (X_testD - meanTrtrue) / stdTrtrue\n",
    "            \n",
    "elif flagTypeMissData == 4 :\n",
    "    #Moyenne des débits par station sur l'échatillon total\n",
    "    M = np.mean(X_trainD,0)\n",
    "    mean_X_trainD = np.mean(M,1)\n",
    "    mean_X_trainD = mean_X_trainD.reshape(31,1)\n",
    "    meanTr        = mean_X_trainD\n",
    "    meanTrtrue = meanTr\n",
    "    #Moyenne des débits\n",
    "    X_nomask=X_trainD[:,:,:(int(2*DT/3+1))]\n",
    "    M2 = np.mean(X_nomask,0)\n",
    "    mean_X_train_missingD = np.mean(M2,1)\n",
    "    mean_X_train_missingD = mean_X_train_missingD.reshape(31,1)\n",
    "\n",
    "    #Ecart-type:\n",
    "    meansquaretrue = np.mean( (X_trainD-mean_X_trainD)**2,0)\n",
    "    meansquare2true = np.mean(meansquaretrue,1)\n",
    "    meansquare2true=meansquare2true.reshape(31,1)\n",
    "    stdTrtrue           = np.sqrt(meansquare2true )\n",
    "    \n",
    "    #Normalisation et standardisation des données\n",
    "    x_train_missingD = np.zeros(X_train_missingD.shape)\n",
    "    x_train_missingD[:,:,:(int(2*DT/3)+1)]=(X_train_missingD[:,:,:(int(2*DT/3)+1)]-mean_X_trainD)/stdTrtrue\n",
    " \n",
    "    x_val_missingD = np.zeros(X_val_missingD.shape)\n",
    "    x_val_missingD[:,:,:(int(2*DT/3)+1)]=(X_val_missingD[:,:,:(int(2*DT/3)+1)]-mean_X_trainD)/stdTrtrue\n",
    "\n",
    "    x_test_missingD = np.zeros(X_test_missingD.shape)\n",
    "    x_test_missingD[:,:,:(int(2*DT/3)+1)]=(X_test_missingD[:,:,:(int(2*DT/3)+1)]-mean_X_trainD)/stdTrtrue\n",
    "\n",
    "\n",
    "    x_trainD = (X_trainD - mean_X_trainD) / stdTrtrue\n",
    "    x_valD = (X_valD - mean_X_trainD) / stdTrtrue\n",
    "    x_testD  = (X_testD - mean_X_trainD) / stdTrtrue\n",
    "    \n",
    "    stdTr =stdTrtrue\n",
    "    \n",
    "else : \n",
    "    mean2 = np.mean(X_train_missingD[:],0)\n",
    "    mean2mask = np.mean(mask_trainD[:],0)\n",
    "            \n",
    "\n",
    "    mean3 = np.mean(mean2,1)\n",
    "    mean3 = mean3.reshape(31,1)\n",
    "    print(mean3)\n",
    "    mean3mask = np.mean(mean2mask,1)\n",
    "    mean3mask = mean3mask.reshape(31,1)\n",
    "    print(mean3mask)\n",
    "    meanTr          = mean3/mean3mask\n",
    "    print(meanTr)\n",
    "            \n",
    "    x_train_missingD = X_train_missingD - meanTr*mask_trainD\n",
    "    x_val_missingD = X_val_missingD - meanTr\n",
    "    x_test_missingD  = X_test_missingD - meanTr\n",
    "            \n",
    "    # scale wrt to each station\n",
    "    meansquare = np.mean( X_train_missingD**2,0)\n",
    "    meansquare2 = np.mean(meansquare,1)\n",
    "    meansquare2=meansquare2.reshape(31,1)\n",
    "    stdTr           = np.sqrt(meansquare2 / mean3mask)\n",
    "            \n",
    "    x_train_missingD = x_train_missingD / stdTr\n",
    "    x_val_missingD = x_val_missingD / stdTr\n",
    "    x_test_missingD  = x_test_missingD / stdTr\n",
    "            \n",
    "    x_trainD = (X_trainD - meanTr) / stdTr\n",
    "    x_valD = (X_valD - meanTr) / stdTr\n",
    "    x_testD  = (X_testD - meanTr) / stdTr\n",
    "            \n",
    "# Generate noisy observsation\n",
    "        \n",
    "#X_train_obsD = X_train_missingD + sigNoise * maskTrainingD * np.random.randn(X_train_missingD.shape[0],X_train_missingD.shape[1],X_train_missingD.shape[2])\n",
    "#X_val_obsD = X_val_missingD + sigNoise * maskValD * np.random.randn(X_val_missingD.shape[0],X_val_missingD.shape[1],X_val_missingD.shape[2])\n",
    "#X_test_obsD  = X_test_missingD  + sigNoise * maskTestD * np.random.randn(X_test_missingD.shape[0],X_test_missingD.shape[1],X_test_missingD.shape[2])\n",
    "            \n",
    "#x_train_obsD = (X_train_obsD - meanTr) / stdTr\n",
    "#x_val_obsD = (X_val_obsD - meanTr) / stdTr\n",
    "#x_test_obsD  = (X_test_obsD - meanTr) / stdTr\n",
    "        \n",
    "#Without noise :\n",
    "X_train_obsD = X_train_missingD \n",
    "X_val_obsD = X_val_missingD \n",
    "X_test_obsD  = X_test_missingD\n",
    "        \n",
    "x_train_obsD = x_train_missingD\n",
    "x_val_obsD = x_val_missingD\n",
    "x_test_obsD = x_test_missingD \n",
    "\n",
    "m_seuil = ((seuil_10.reshape(31,1)-meanTr)/stdTr)\n",
    "print(seuil_10.shape)\n",
    "print(meanTr.shape)\n",
    "print(stdTr.shape)\n",
    "print(\"seuil normalisé\")\n",
    "print(m_seuil)\n",
    "        \n",
    "print('..... Training dataset: %dx%dx%d'%(x_train_missingD.shape[0],x_trainD.shape[1],x_trainD.shape[2]))\n",
    "print('..... Validation dataset: %dx%dx%d'%(x_valD.shape[0],x_valD.shape[1],x_valD.shape[2]))\n",
    "print('..... Test dataset    : %dx%dx%d'%(x_testD.shape[0],x_testD.shape[1],x_testD.shape[2]))\n",
    "            \n",
    "\n",
    "print('........ Initialize interpolated states')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ffdf0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 951.    916.    896.    955.    967.    983.   1040.   1010.   1030.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 524.    543.    513.    510.    513.    581.    597.    581.    589.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 417.    425.    396.    384.    388.    458.    447.    430.    441.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 419.    385.    366.    352.    419.    437.    400.    406.    417.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 314.    282.    272.    258.    328.    335.    297.    305.    299.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 288.    260.    247.    237.    310.    308.    277.    282.    273.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 248.    236.    231.    238.    321.    306.    269.    252.    245.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 200.    181.    163.    182.    227.    204.    193.    190.    178.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 168.    155.    129.    181.    205.    167.    162.    155.    142.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 135.    125.    106.    170.    165.    133.    129.    123.    108.\n",
      "     0.      0.      0.      0.  ]\n",
      " [  36.3    29.9    52.    109.     63.6    46.     44.6    35.2    31.5\n",
      "     0.      0.      0.      0.  ]\n",
      " [  11.2     9.77   18.     24.5    14.6    13.1    10.9     9.77    8.78\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 341.    319.    319.    363.    366.    353.    369.    350.    366.\n",
      "     0.      0.      0.      0.  ]\n",
      " [  98.8    98.8    99.9   105.    119.    117.    113.    126.    116.\n",
      "     0.      0.      0.      0.  ]\n",
      " [  89.1    95.     95.    104.    110.    104.    113.    110.    104.\n",
      "     0.      0.      0.      0.  ]\n",
      " [  17.5    14.3    16.     33.     26.4    25.1    23.2    21.5    18.5\n",
      "     0.      0.      0.      0.  ]\n",
      " [  20.1    19.8    20.7    27.2    23.5    23.1    22.8    22.1    20.7\n",
      "     0.      0.      0.      0.  ]\n",
      " [  15.8    14.7    23.3    24.8    18.1    18.7    16.9    16.3    14.7\n",
      "     0.      0.      0.      0.  ]\n",
      " [   8.56    8.17   10.9    15.1    12.6    12.     10.9    10.9    10.4\n",
      "     0.      0.      0.      0.  ]\n",
      " [  51.1    49.5    52.7    71.7    82.6    65.2    63.3    61.4    61.4\n",
      "     0.      0.      0.      0.  ]\n",
      " [  19.     32.7    33.9    35.2    57.9    38.     43.5    42.1    38.\n",
      "     0.      0.      0.      0.  ]\n",
      " [  15.6    25.6    23.6    35.     35.9    24.8    31.6    35.     31.6\n",
      "     0.      0.      0.      0.  ]\n",
      " [  52.5    52.5    54.9    53.7    56.1    51.3    52.5    60.9    73.1\n",
      "     0.      0.      0.      0.  ]\n",
      " [  47.5    39.3    36.7    40.2    39.3    35.     38.4    48.5    55.5\n",
      "     0.      0.      0.      0.  ]\n",
      " [  37.5    31.7    30.5    37.5    44.3    42.2    37.5    38.8    40.8\n",
      "     0.      0.      0.      0.  ]\n",
      " [  31.3    26.8    31.3    32.9    40.5    35.4    29.     34.5    31.3\n",
      "     0.      0.      0.      0.  ]\n",
      " [  26.1    23.1    28.3    31.6    31.6    28.3    26.1    26.1    21.1\n",
      "     0.      0.      0.      0.  ]\n",
      " [  21.4    22.1    23.6    25.9    21.8    21.     20.     18.8    17.5\n",
      "     0.      0.      0.      0.  ]\n",
      " [  17.     17.     15.8    19.5    18.2    18.8    17.6    14.7    14.2\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 130.    123.    121.    151.    137.    135.    127.    126.    132.\n",
      "     0.      0.      0.      0.  ]\n",
      " [ 110.    108.    136.    153.    131.    137.    110.    115.    111.\n",
      "     0.      0.      0.      0.  ]]\n"
     ]
    }
   ],
   "source": [
    "## Initial interpolation\n",
    "#flagInit = 0 : Masked values are replaced by 0\n",
    "#flagInit = 1 : masked values are replaced by last available value (prevision)\n",
    "#flaginit = 2 : Interpolation \n",
    "\n",
    "flagInit = 1\n",
    "print(X_train_missingD[0,:,:])\n",
    "            \n",
    "if flagInit == 0: \n",
    "    X_train_InitD = mask_trainD * X_train_obsD + (1. - mask_trainD) * (np.zeros(X_train_missingD.shape) + meanTr)\n",
    "    X_val_InitD = mask_valD * X_val_obsD + (1. - mask_valD) * (np.zeros(X_val_missingD.shape) + meanTr)\n",
    "    X_test_InitD  = mask_testD * X_test_obsD + (1. - mask_testD) * (np.zeros(X_test_missingD.shape) + meanTr)\n",
    "    \n",
    "elif flagInit==1 :\n",
    "    X_ext_train = X_train_missingD[:,:,int(2*DT/3)].reshape(X_train_missingD.shape[0],X_train_missingD.shape[1],1)\n",
    "    X_train_InitD = mask_trainD * X_train_obsD + (1. - mask_trainD)*X_ext_train\n",
    "    X_ext_val = X_val_missingD[:,:,int(2*DT/3)].reshape(X_val_missingD.shape[0],X_val_missingD.shape[1],1)\n",
    "    X_train_InitD = mask_valD * X_val_obsD + (1. - mask_valD)*X_ext_val\n",
    "    X_ext_test = X_test_missingD[:,:,int(2*DT/3)].reshape(X_test_missingD.shape[0],X_test_missingD.shape[1],1)\n",
    "    X_testInitD = mask_testD * X_test_obsD + (1. - mask_testD)*X_ext_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d0719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[ 951.   916.   896.   955.   967.   983.  1040.  1010.  1030.   979.\n",
      "   885.   799.   775.   719.   719.   698.   664.   639.   658.   695.\n",
      "   680. ]\n",
      " [ 524.   543.   513.   510.   513.   581.   597.   581.   589.   581.\n",
      "   535.   471.   428.   404.   385.   370.   364.   361.   358.   382.\n",
      "   379. ]\n",
      " [ 417.   425.   396.   384.   388.   458.   447.   430.   441.   439.\n",
      "   394.   329.   308.   287.   259.   251.   249.   247.   249.   278.\n",
      "   274. ]\n",
      " [ 419.   385.   366.   352.   419.   437.   400.   406.   417.   402.\n",
      "   324.   294.   280.   265.   245.   242.   240.   238.   245.   260.\n",
      "   264. ]\n",
      " [ 314.   282.   272.   258.   328.   335.   297.   305.   299.   288.\n",
      "   249.   235.   218.   214.   211.   211.   204.   186.   195.   193.\n",
      "   191. ]\n",
      " [ 288.   260.   247.   237.   310.   308.   277.   282.   273.   260.\n",
      "   220.   214.   197.   191.   195.   198.   195.   181.   187.   174.\n",
      "   176. ]\n",
      " [ 248.   236.   231.   238.   321.   306.   269.   252.   245.   228.\n",
      "   185.   180.   171.   165.   178.   185.   165.   149.   158.   156.\n",
      "   158. ]\n",
      " [ 200.   181.   163.   182.   227.   204.   193.   190.   178.   165.\n",
      "   135.   124.   125.   114.   110.   103.    96.    95.1   99.   100.\n",
      "   100. ]\n",
      " [ 168.   155.   129.   181.   205.   167.   162.   155.   142.   122.\n",
      "   102.    99.2  102.    94.2  102.    97.9   91.7   86.7   85.5   85.5\n",
      "    88. ]\n",
      " [ 135.   125.   106.   170.   165.   133.   129.   123.   108.    87.6\n",
      "    80.1   81.1   80.1   75.9   72.8   69.1   61.9   66.3   68.2   66.3\n",
      "    69.1]\n",
      " [  36.3   29.9   52.   109.    63.6   46.    44.6   35.2   31.5   24.9\n",
      "    27.    27.    25.9   24.4   23.9   20.1   18.5   21.    20.1   20.1\n",
      "    21.4]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]]\n",
      "(13110, 31, 21)\n"
     ]
    }
   ],
   "source": [
    "                                \n",
    "# mask for NaN\n",
    "maskTrainingD = (dataTrainingD == dataTrainingD).astype('float')\n",
    "maskValD = (dataValD == dataValD).astype('float')\n",
    "maskTestD     = ( dataTestD    ==  dataTestD   ).astype('float')\n",
    "print(maskTrainingD[0,:,:])\n",
    "            \n",
    "dataTrainingD = np.nan_to_num(dataTrainingD)       \n",
    "dataValD = np.nan_to_num(dataValD)\n",
    "dataTestD     = np.nan_to_num(dataTestD)\n",
    "print(dataTrainingD[0,:,:])\n",
    "print(dataTrainingD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e077e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13110, 31, 21)\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "    # Permutation to have channel as #1 component\n",
    "dataTrainingD      = np.moveaxis(dataTrainingD,-1,1)\n",
    "maskTrainingD      = np.moveaxis(maskTrainingD,-1,1)\n",
    "dataTrainingNoNaND = np.moveaxis(dataTrainingNoNaND,-1,1)\n",
    "print(dataTrainingD.shape)\n",
    "        \n",
    "dataValD      = np.moveaxis(dataValD,-1,1)\n",
    "maskValD      = np.moveaxis(maskValD,-1,1)\n",
    "dataValNoNaND = np.moveaxis(dataValNoNaND,-1,1)\n",
    "            \n",
    "dataTestD      = np.moveaxis(dataTestD,-1,1)\n",
    "maskTestD      = np.moveaxis(maskTestD,-1,1)\n",
    "dataTestNoNaND = np.moveaxis(dataTestNoNaND,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e2b7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 951.    916.    896.    955.    967.    983.   1040.   1010.   1030.\n",
      "   979.    885.    799.    775.    719.    719.    698.    664.    639.\n",
      "   658.    695.    680.  ]\n",
      " [ 524.    543.    513.    510.    513.    581.    597.    581.    589.\n",
      "   581.    535.    471.    428.    404.    385.    370.    364.    361.\n",
      "   358.    382.    379.  ]\n",
      " [ 417.    425.    396.    384.    388.    458.    447.    430.    441.\n",
      "   439.    394.    329.    308.    287.    259.    251.    249.    247.\n",
      "   249.    278.    274.  ]\n",
      " [ 419.    385.    366.    352.    419.    437.    400.    406.    417.\n",
      "   402.    324.    294.    280.    265.    245.    242.    240.    238.\n",
      "   245.    260.    264.  ]\n",
      " [ 314.    282.    272.    258.    328.    335.    297.    305.    299.\n",
      "   288.    249.    235.    218.    214.    211.    211.    204.    186.\n",
      "   195.    193.    191.  ]\n",
      " [ 288.    260.    247.    237.    310.    308.    277.    282.    273.\n",
      "   260.    220.    214.    197.    191.    195.    198.    195.    181.\n",
      "   187.    174.    176.  ]\n",
      " [ 248.    236.    231.    238.    321.    306.    269.    252.    245.\n",
      "   228.    185.    180.    171.    165.    178.    185.    165.    149.\n",
      "   158.    156.    158.  ]\n",
      " [ 200.    181.    163.    182.    227.    204.    193.    190.    178.\n",
      "   165.    135.    124.    125.    114.    110.    103.     96.     95.1\n",
      "    99.    100.    100.  ]\n",
      " [ 168.    155.    129.    181.    205.    167.    162.    155.    142.\n",
      "   122.    102.     99.2   102.     94.2   102.     97.9    91.7    86.7\n",
      "    85.5    85.5    88.  ]\n",
      " [ 135.    125.    106.    170.    165.    133.    129.    123.    108.\n",
      "    87.6    80.1    81.1    80.1    75.9    72.8    69.1    61.9    66.3\n",
      "    68.2    66.3    69.1 ]\n",
      " [  36.3    29.9    52.    109.     63.6    46.     44.6    35.2    31.5\n",
      "    24.9    27.     27.     25.9    24.4    23.9    20.1    18.5    21.\n",
      "    20.1    20.1    21.4 ]\n",
      " [  11.2     9.77   18.     24.5    14.6    13.1    10.9     9.77    8.78\n",
      "     7.79    6.49    6.49    6.18    5.56    4.94    4.63    4.32    4.32\n",
      "     4.01    4.32    5.56]\n",
      " [ 341.    319.    319.    363.    366.    353.    369.    350.    366.\n",
      "   347.    338.    324.    333.    316.    344.    369.    338.    313.\n",
      "   307.    313.    305.  ]\n",
      " [  98.8    98.8    99.9   105.    119.    117.    113.    126.    116.\n",
      "   115.    109.    112.    108.    105.    109.    112.    109.    108.\n",
      "   105.    101.     99.9 ]\n",
      " [  89.1    95.     95.    104.    110.    104.    113.    110.    104.\n",
      "   101.     92.     92.     92.     92.     98.    113.    113.    113.\n",
      "   107.     98.     95.  ]\n",
      " [  17.5    14.3    16.     33.     26.4    25.1    23.2    21.5    18.5\n",
      "    16.     15.1    14.7    15.6    21.5    27.8    23.2    19.     13.\n",
      "    13.4    14.7    16.  ]\n",
      " [  20.1    19.8    20.7    27.2    23.5    23.1    22.8    22.1    20.7\n",
      "    20.7    20.7    20.1    19.8    19.5    21.4    22.4    20.7    19.5\n",
      "    18.7    19.     19.2 ]\n",
      " [  15.8    14.7    23.3    24.8    18.1    18.7    16.9    16.3    14.7\n",
      "    13.1    12.6    12.6    12.6    12.6    12.1    11.7    11.7    11.2\n",
      "    10.8    10.8    11.2 ]\n",
      " [   8.56    8.17   10.9    15.1    12.6    12.     10.9    10.9    10.4\n",
      "     9.42    9.42    9.42    9.42    9.42    9.42    8.98    8.98    8.98\n",
      "     9.42    9.42    9.42]\n",
      " [  51.1    49.5    52.7    71.7    82.6    65.2    63.3    61.4    61.4\n",
      "    51.1    51.1    52.7    52.7    51.1    51.1    51.1    48.2    54.3\n",
      "    54.3    55.9    61.4 ]\n",
      " [  19.     32.7    33.9    35.2    57.9    38.     43.5    42.1    38.\n",
      "    31.5    38.     42.1    42.1    42.1    42.1    42.1    36.6    42.1\n",
      "    39.4    44.9    50.5 ]\n",
      " [  15.6    25.6    23.6    35.     35.9    24.8    31.6    35.     31.6\n",
      "    21.8    33.3    33.3    38.5    35.     36.8    33.3    19.4    52.1\n",
      "    64.6    65.7    58.8 ]\n",
      " [  52.5    52.5    54.9    53.7    56.1    51.3    52.5    60.9    73.1\n",
      "    65.7    45.3    35.7    34.5    30.9    30.9    30.9    29.7    28.5\n",
      "    30.9    30.9    32.1 ]\n",
      " [  47.5    39.3    36.7    40.2    39.3    35.     38.4    48.5    55.5\n",
      "    47.5    27.     25.5    22.7    19.2    22.7    21.3    20.6    20.6\n",
      "    23.3    23.3    22.7 ]\n",
      " [  37.5    31.7    30.5    37.5    44.3    42.2    37.5    38.8    40.8\n",
      "    24.9    16.8    24.3    17.8    15.4    22.6    18.8    20.9    22.6\n",
      "    17.8    23.7    21.5 ]\n",
      " [  31.3    26.8    31.3    32.9    40.5    35.4    29.     34.5    31.3\n",
      "    16.8    17.9    14.6    16.2    13.5    15.7    15.7    14.6    17.3\n",
      "    15.7    15.7    15.7 ]\n",
      " [  26.1    23.1    28.3    31.6    31.6    28.3    26.1    26.1    21.1\n",
      "    15.2    15.2    11.6    13.4    10.7    13.4    12.5    11.6    14.3\n",
      "    13.4    13.4    13.4 ]\n",
      " [  21.4    22.1    23.6    25.9    21.8    21.     20.     18.8    17.5\n",
      "    14.4    12.8    10.6    10.3    10.9    10.5    10.5    10.5    10.3\n",
      "    10.3     9.68    9.07]\n",
      " [  17.     17.     15.8    19.5    18.2    18.8    17.6    14.7    14.2\n",
      "    13.7    11.8    11.     10.6     9.8     9.8     9.8     9.46    9.8\n",
      "     9.46    9.46    9.13]\n",
      " [ 130.    123.    121.    151.    137.    135.    127.    126.    132.\n",
      "   113.     93.1   101.    104.     97.7    96.8    99.4    92.1    83.9\n",
      "    84.6    82.7    83.5 ]\n",
      " [ 110.    108.    136.    153.    131.    137.    110.    115.    111.\n",
      "   103.     70.9    79.3    84.6    75.2    73.9    75.     69.1    61.5\n",
      "    69.6    71.1    71.4 ]]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "############################################\n",
    "## raw data\n",
    "X_trainD         = dataTrainingNoNaND\n",
    "print(X_trainD[0,:,:]) \n",
    "\n",
    "X_train_missingD = dataTrainingD\n",
    "mask_trainD      = maskTrainingD\n",
    "        \n",
    "X_valD         = dataValNoNaND\n",
    "X_val_missingD = dataValD\n",
    "mask_valD      = maskValD\n",
    "        \n",
    "X_testD         = dataTestNoNaND\n",
    "X_test_missingD = dataTestD\n",
    "mask_testD      = maskTestD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de9cf278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1408.37557662]\n",
      " [ 636.36608914]\n",
      " [ 459.14530892]\n",
      " [ 447.40899277]\n",
      " [ 355.3643184 ]\n",
      " [ 333.40624605]\n",
      " [ 313.73274018]\n",
      " [ 194.55132614]\n",
      " [ 164.09714031]\n",
      " [ 123.86010497]\n",
      " [  45.9025836 ]\n",
      " [  20.95774233]\n",
      " [ 732.38325524]\n",
      " [ 171.11155352]\n",
      " [ 159.6648647 ]\n",
      " [  62.17256678]\n",
      " [  47.17658458]\n",
      " [  27.01952079]\n",
      " [  19.73095558]\n",
      " [ 112.2873183 ]\n",
      " [  78.91576623]\n",
      " [  69.71982834]\n",
      " [  49.63537213]\n",
      " [  37.71062816]\n",
      " [  37.23651324]\n",
      " [  33.88651226]\n",
      " [  25.67607254]\n",
      " [  41.12310799]\n",
      " [  36.89404551]\n",
      " [ 251.04848534]\n",
      " [ 236.36415386]]\n",
      "[[ 951.   916.   896.   955.   967.   983.  1040.  1010.  1030.   979.\n",
      "   885.   799.   775.   719.   719.   698.   664.   639.   658.   695.\n",
      "   680. ]\n",
      " [ 524.   543.   513.   510.   513.   581.   597.   581.   589.   581.\n",
      "   535.   471.   428.   404.   385.   370.   364.   361.   358.   382.\n",
      "   379. ]\n",
      " [ 417.   425.   396.   384.   388.   458.   447.   430.   441.   439.\n",
      "   394.   329.   308.   287.   259.   251.   249.   247.   249.   278.\n",
      "   274. ]\n",
      " [ 419.   385.   366.   352.   419.   437.   400.   406.   417.   402.\n",
      "   324.   294.   280.   265.   245.   242.   240.   238.   245.   260.\n",
      "   264. ]\n",
      " [ 314.   282.   272.   258.   328.   335.   297.   305.   299.   288.\n",
      "   249.   235.   218.   214.   211.   211.   204.   186.   195.   193.\n",
      "   191. ]\n",
      " [ 288.   260.   247.   237.   310.   308.   277.   282.   273.   260.\n",
      "   220.   214.   197.   191.   195.   198.   195.   181.   187.   174.\n",
      "   176. ]\n",
      " [ 248.   236.   231.   238.   321.   306.   269.   252.   245.   228.\n",
      "   185.   180.   171.   165.   178.   185.   165.   149.   158.   156.\n",
      "   158. ]\n",
      " [ 200.   181.   163.   182.   227.   204.   193.   190.   178.   165.\n",
      "   135.   124.   125.   114.   110.   103.    96.    95.1   99.   100.\n",
      "   100. ]\n",
      " [ 168.   155.   129.   181.   205.   167.   162.   155.   142.   122.\n",
      "   102.    99.2  102.    94.2  102.    97.9   91.7   86.7   85.5   85.5\n",
      "    88. ]\n",
      " [ 135.   125.   106.   170.   165.   133.   129.   123.   108.    87.6\n",
      "    80.1   81.1   80.1   75.9   72.8   69.1   61.9   66.3   68.2   66.3\n",
      "    69.1]\n",
      " [  36.3   29.9   52.   109.    63.6   46.    44.6   35.2   31.5   24.9\n",
      "    27.    27.    25.9   24.4   23.9   20.1   18.5   21.    20.1   20.1\n",
      "    21.4]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]]\n",
      "[[1409.32945704]\n",
      " [ 636.84923376]\n",
      " [ 459.48457805]\n",
      " [ 447.7983205 ]\n",
      " [ 355.6745614 ]\n",
      " [ 333.67699605]\n",
      " [ 313.9910873 ]\n",
      " [ 194.70429651]\n",
      " [ 164.20456487]\n",
      " [ 123.96628042]\n",
      " [  45.95327092]\n",
      " [  20.97771632]\n",
      " [ 732.70513834]\n",
      " [ 171.31317662]\n",
      " [ 159.88584148]\n",
      " [  62.24805742]\n",
      " [  47.23160807]\n",
      " [  27.04651605]\n",
      " [  19.77300187]\n",
      " [ 112.34901116]\n",
      " [  78.95793288]\n",
      " [  69.75107177]\n",
      " [  49.63295888]\n",
      " [  37.70745559]\n",
      " [  37.29201741]\n",
      " [  33.93808918]\n",
      " [  25.71273289]\n",
      " [  41.1994438 ]\n",
      " [  36.96295728]\n",
      " [ 251.2337695 ]\n",
      " [ 236.53780875]]\n"
     ]
    }
   ],
   "source": [
    "M = np.mean(X_trainD,0)\n",
    "mean_X_trainD = np.mean(M,1)\n",
    "mean_X_trainD = mean_X_trainD.reshape(31,1)\n",
    "print(mean_X_trainD)\n",
    "X_nomask=X_trainD[:,:,:(int(DT/2+1))]\n",
    "M2 = np.mean(X_nomask,0)\n",
    "mean_X_train_missingD = np.mean(M2,1)\n",
    "mean_X_train_missingD = mean_X_train_missingD.reshape(31,1)\n",
    "print(X_train_missingD[0,:,:])\n",
    "print(mean_X_train_missingD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e5aa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[612.39963356]\n",
      " [301.53800676]\n",
      " [241.94437468]\n",
      " [235.74525246]\n",
      " [181.97537275]\n",
      " [167.4923211 ]\n",
      " [161.85841078]\n",
      " [112.3070918 ]\n",
      " [ 93.3841133 ]\n",
      " [ 75.37628723]\n",
      " [ 39.46083081]\n",
      " [ 18.93179983]\n",
      " [387.78114172]\n",
      " [ 68.23159229]\n",
      " [ 67.52888901]\n",
      " [ 49.0323657 ]\n",
      " [ 30.61545913]\n",
      " [ 22.18802769]\n",
      " [ 20.00366379]\n",
      " [ 61.98118642]\n",
      " [ 48.83232821]\n",
      " [ 46.25917901]\n",
      " [ 40.72237208]\n",
      " [ 35.63603417]\n",
      " [ 29.91950783]\n",
      " [ 27.20402553]\n",
      " [ 20.27271707]\n",
      " [ 33.27746701]\n",
      " [ 31.37399001]\n",
      " [161.98665692]\n",
      " [152.0257904 ]]\n"
     ]
    }
   ],
   "source": [
    "meansquaretrue = np.mean( (X_trainD-mean_X_trainD)**2,0)\n",
    "meansquare2true = np.mean(meansquaretrue,1)\n",
    "meansquare2true=meansquare2true.reshape(31,1)\n",
    "stdTrtrue           = np.sqrt(meansquare2true )\n",
    "print(stdTrtrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "444fc121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 951.   916.   896.   955.   967.   983.  1040.  1010.  1030.   979.\n",
      "   885.   799.   775.   719.   719.   698.   664.   639.   658.   695.\n",
      "   680. ]\n",
      " [ 524.   543.   513.   510.   513.   581.   597.   581.   589.   581.\n",
      "   535.   471.   428.   404.   385.   370.   364.   361.   358.   382.\n",
      "   379. ]\n",
      " [ 417.   425.   396.   384.   388.   458.   447.   430.   441.   439.\n",
      "   394.   329.   308.   287.   259.   251.   249.   247.   249.   278.\n",
      "   274. ]\n",
      " [ 419.   385.   366.   352.   419.   437.   400.   406.   417.   402.\n",
      "   324.   294.   280.   265.   245.   242.   240.   238.   245.   260.\n",
      "   264. ]\n",
      " [ 314.   282.   272.   258.   328.   335.   297.   305.   299.   288.\n",
      "   249.   235.   218.   214.   211.   211.   204.   186.   195.   193.\n",
      "   191. ]\n",
      " [ 288.   260.   247.   237.   310.   308.   277.   282.   273.   260.\n",
      "   220.   214.   197.   191.   195.   198.   195.   181.   187.   174.\n",
      "   176. ]\n",
      " [ 248.   236.   231.   238.   321.   306.   269.   252.   245.   228.\n",
      "   185.   180.   171.   165.   178.   185.   165.   149.   158.   156.\n",
      "   158. ]\n",
      " [ 200.   181.   163.   182.   227.   204.   193.   190.   178.   165.\n",
      "   135.   124.   125.   114.   110.   103.    96.    95.1   99.   100.\n",
      "   100. ]\n",
      " [ 168.   155.   129.   181.   205.   167.   162.   155.   142.   122.\n",
      "   102.    99.2  102.    94.2  102.    97.9   91.7   86.7   85.5   85.5\n",
      "    88. ]\n",
      " [ 135.   125.   106.   170.   165.   133.   129.   123.   108.    87.6\n",
      "    80.1   81.1   80.1   75.9   72.8   69.1   61.9   66.3   68.2   66.3\n",
      "    69.1]\n",
      " [  36.3   29.9   52.   109.    63.6   46.    44.6   35.2   31.5   24.9\n",
      "    27.    27.    25.9   24.4   23.9   20.1   18.5   21.    20.1   20.1\n",
      "    21.4]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0. ]]\n",
      "[[-7.46858018e-01 -8.04010240e-01 -8.36668653e-01 -7.40326336e-01\n",
      "  -7.20731288e-01 -6.94604558e-01 -6.01528081e-01 -6.50515701e-01\n",
      "  -6.17857288e-01 -7.01136240e-01 -8.54630780e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-3.72643205e-01 -3.09632905e-01 -4.09122851e-01 -4.19071846e-01\n",
      "  -4.09122851e-01 -1.83612307e-01 -1.30551003e-01 -1.83612307e-01\n",
      "  -1.57081655e-01 -1.83612307e-01 -3.36163558e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.74194209e-01 -1.41128757e-01 -2.60991019e-01 -3.10589196e-01\n",
      "  -2.94056471e-01 -4.73376959e-03 -5.01987655e-02 -1.20462850e-01\n",
      "  -7.49978541e-02 -8.32642170e-02 -2.69257382e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.20507168e-01 -2.64730645e-01 -3.45326118e-01 -4.04712255e-01\n",
      "  -1.20507168e-01 -4.41535626e-02 -2.01102641e-01 -1.75651439e-01\n",
      "  -1.28990902e-01 -1.92618907e-01 -5.23484530e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.27307233e-01 -4.03155203e-01 -4.58107694e-01 -5.35041181e-01\n",
      "  -1.50373746e-01 -1.11907002e-01 -3.20726467e-01 -2.76764474e-01\n",
      "  -3.09735969e-01 -3.70183709e-01 -5.84498423e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.71094494e-01 -4.38266337e-01 -5.15881836e-01 -5.75586065e-01\n",
      "  -1.39745189e-01 -1.51686035e-01 -3.36769147e-01 -3.06917032e-01\n",
      "  -3.60650839e-01 -4.38266337e-01 -6.77083256e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-4.06112601e-01 -4.80251473e-01 -5.11142670e-01 -4.67894994e-01\n",
      "   4.48988704e-02 -4.77747196e-02 -2.76369575e-01 -3.81399644e-01\n",
      "  -4.24647319e-01 -5.29677388e-01 -7.95341679e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 4.85158486e-02 -1.20663138e-01 -2.80937968e-01 -1.11758981e-01\n",
      "   2.88928093e-01  8.41324774e-02 -1.38132518e-02 -4.05257234e-02\n",
      "  -1.47375610e-01 -2.63129653e-01 -5.30254369e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 4.17936151e-02 -9.74163591e-02 -3.75836307e-01  1.81003589e-01\n",
      "   4.38006618e-01  3.10851555e-02 -2.24571422e-02 -9.74163591e-02\n",
      "  -2.36626333e-01 -4.50795524e-01 -6.64964715e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.47790445e-01  1.51227272e-02 -2.36945937e-01  6.12127457e-01\n",
      "   5.45793598e-01  1.21256901e-01  6.81898143e-02 -1.14108164e-02\n",
      "  -2.10412393e-01 -4.81054537e-01 -5.80555326e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.43344689e-01 -4.05530833e-01  1.54518196e-01  1.59898854e+00\n",
      "   4.48480583e-01  2.46868607e-03 -3.30095330e-02 -2.71220432e-01\n",
      "  -3.64984297e-01 -5.32238758e-01 -4.79021430e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.10701267e+00 -1.10701267e+00 -1.10701267e+00 -1.10701267e+00\n",
      "  -1.10701267e+00 -1.10701267e+00 -1.10701267e+00 -1.10701267e+00\n",
      "  -1.10701267e+00 -1.10701267e+00 -1.10701267e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.88865104e+00 -1.88865104e+00 -1.88865104e+00 -1.88865104e+00\n",
      "  -1.88865104e+00 -1.88865104e+00 -1.88865104e+00 -1.88865104e+00\n",
      "  -1.88865104e+00 -1.88865104e+00 -1.88865104e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.50780537e+00 -2.50780537e+00 -2.50780537e+00 -2.50780537e+00\n",
      "  -2.50780537e+00 -2.50780537e+00 -2.50780537e+00 -2.50780537e+00\n",
      "  -2.50780537e+00 -2.50780537e+00 -2.50780537e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.36439348e+00 -2.36439348e+00 -2.36439348e+00 -2.36439348e+00\n",
      "  -2.36439348e+00 -2.36439348e+00 -2.36439348e+00 -2.36439348e+00\n",
      "  -2.36439348e+00 -2.36439348e+00 -2.36439348e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.26799035e+00 -1.26799035e+00 -1.26799035e+00 -1.26799035e+00\n",
      "  -1.26799035e+00 -1.26799035e+00 -1.26799035e+00 -1.26799035e+00\n",
      "  -1.26799035e+00 -1.26799035e+00 -1.26799035e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.54093997e+00 -1.54093997e+00 -1.54093997e+00 -1.54093997e+00\n",
      "  -1.54093997e+00 -1.54093997e+00 -1.54093997e+00 -1.54093997e+00\n",
      "  -1.54093997e+00 -1.54093997e+00 -1.54093997e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.21775226e+00 -1.21775226e+00 -1.21775226e+00 -1.21775226e+00\n",
      "  -1.21775226e+00 -1.21775226e+00 -1.21775226e+00 -1.21775226e+00\n",
      "  -1.21775226e+00 -1.21775226e+00 -1.21775226e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-9.86367087e-01 -9.86367087e-01 -9.86367087e-01 -9.86367087e-01\n",
      "  -9.86367087e-01 -9.86367087e-01 -9.86367087e-01 -9.86367087e-01\n",
      "  -9.86367087e-01 -9.86367087e-01 -9.86367087e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.81163551e+00 -1.81163551e+00 -1.81163551e+00 -1.81163551e+00\n",
      "  -1.81163551e+00 -1.81163551e+00 -1.81163551e+00 -1.81163551e+00\n",
      "  -1.81163551e+00 -1.81163551e+00 -1.81163551e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.61605578e+00 -1.61605578e+00 -1.61605578e+00 -1.61605578e+00\n",
      "  -1.61605578e+00 -1.61605578e+00 -1.61605578e+00 -1.61605578e+00\n",
      "  -1.61605578e+00 -1.61605578e+00 -1.61605578e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.50715663e+00 -1.50715663e+00 -1.50715663e+00 -1.50715663e+00\n",
      "  -1.50715663e+00 -1.50715663e+00 -1.50715663e+00 -1.50715663e+00\n",
      "  -1.50715663e+00 -1.50715663e+00 -1.50715663e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.21887232e+00 -1.21887232e+00 -1.21887232e+00 -1.21887232e+00\n",
      "  -1.21887232e+00 -1.21887232e+00 -1.21887232e+00 -1.21887232e+00\n",
      "  -1.21887232e+00 -1.21887232e+00 -1.21887232e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.05821619e+00 -1.05821619e+00 -1.05821619e+00 -1.05821619e+00\n",
      "  -1.05821619e+00 -1.05821619e+00 -1.05821619e+00 -1.05821619e+00\n",
      "  -1.05821619e+00 -1.05821619e+00 -1.05821619e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.24455634e+00 -1.24455634e+00 -1.24455634e+00 -1.24455634e+00\n",
      "  -1.24455634e+00 -1.24455634e+00 -1.24455634e+00 -1.24455634e+00\n",
      "  -1.24455634e+00 -1.24455634e+00 -1.24455634e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.24564330e+00 -1.24564330e+00 -1.24564330e+00 -1.24564330e+00\n",
      "  -1.24564330e+00 -1.24564330e+00 -1.24564330e+00 -1.24564330e+00\n",
      "  -1.24564330e+00 -1.24564330e+00 -1.24564330e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.26653336e+00 -1.26653336e+00 -1.26653336e+00 -1.26653336e+00\n",
      "  -1.26653336e+00 -1.26653336e+00 -1.26653336e+00 -1.26653336e+00\n",
      "  -1.26653336e+00 -1.26653336e+00 -1.26653336e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.23576437e+00 -1.23576437e+00 -1.23576437e+00 -1.23576437e+00\n",
      "  -1.23576437e+00 -1.23576437e+00 -1.23576437e+00 -1.23576437e+00\n",
      "  -1.23576437e+00 -1.23576437e+00 -1.23576437e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.17594369e+00 -1.17594369e+00 -1.17594369e+00 -1.17594369e+00\n",
      "  -1.17594369e+00 -1.17594369e+00 -1.17594369e+00 -1.17594369e+00\n",
      "  -1.17594369e+00 -1.17594369e+00 -1.17594369e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.54980966e+00 -1.54980966e+00 -1.54980966e+00 -1.54980966e+00\n",
      "  -1.54980966e+00 -1.54980966e+00 -1.54980966e+00 -1.54980966e+00\n",
      "  -1.54980966e+00 -1.54980966e+00 -1.54980966e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.55476353e+00 -1.55476353e+00 -1.55476353e+00 -1.55476353e+00\n",
      "  -1.55476353e+00 -1.55476353e+00 -1.55476353e+00 -1.55476353e+00\n",
      "  -1.55476353e+00 -1.55476353e+00 -1.55476353e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "x_train_missingD = np.zeros(X_train_missingD.shape)\n",
    "print(X_train_missingD[0,:,:])\n",
    "x_train_missingD[:,:,:(int(DT/2)+1)]=(X_train_missingD[:,:,:(int(DT/2)+1)]-mean_X_trainD)/stdTrtrue\n",
    "print(x_train_missingD[0,:,:])\n",
    "x_val_missingD = np.zeros(X_val_missingD.shape)\n",
    "x_val_missingD[:,:,:(int(DT/2)+1)]=(X_val_missingD[:,:,:(int(DT/2)+1)]-mean_X_trainD)/stdTrtrue\n",
    "\n",
    "x_test_missingD = np.zeros(X_test_missingD.shape)\n",
    "x_test_missingD[:,:,:(int(DT/2)+1)]=(X_test_missingD[:,:,:(int(DT/2)+1)]-mean_X_trainD)/stdTrtrue\n",
    "\n",
    "\n",
    "x_trainD = (X_trainD - mean_X_trainD) / stdTrtrue\n",
    "x_valD = (X_valD - mean_X_trainD) / stdTrtrue\n",
    "x_testD  = (X_testD - mean_X_trainD) / stdTrtrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "340b1737",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "#Without noise :\n",
    "X_train_obsD = X_train_missingD \n",
    "X_val_obsD = X_val_missingD \n",
    "X_test_obsD  = X_test_missingD\n",
    "        \n",
    "x_train_obsD = x_train_missingD\n",
    "x_val_obsD = x_val_missingD\n",
    "x_test_obsD = x_test_missingD \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd02f87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 951.          916.          896.          955.          967.\n",
      "   983.         1040.         1010.         1030.          979.\n",
      "   885.          799.          775.          719.          719.\n",
      "   698.          664.          639.          658.          695.\n",
      "   680.        ]\n",
      " [ 524.          543.          513.          510.          513.\n",
      "   581.          597.          581.          589.          581.\n",
      "   535.          471.          428.          404.          385.\n",
      "   370.          364.          361.          358.          382.\n",
      "   379.        ]\n",
      " [ 417.          425.          396.          384.          388.\n",
      "   458.          447.          430.          441.          439.\n",
      "   394.          329.          308.          287.          259.\n",
      "   251.          249.          247.          249.          278.\n",
      "   274.        ]\n",
      " [ 419.          385.          366.          352.          419.\n",
      "   437.          400.          406.          417.          402.\n",
      "   324.          294.          280.          265.          245.\n",
      "   242.          240.          238.          245.          260.\n",
      "   264.        ]\n",
      " [ 314.          282.          272.          258.          328.\n",
      "   335.          297.          305.          299.          288.\n",
      "   249.          235.          218.          214.          211.\n",
      "   211.          204.          186.          195.          193.\n",
      "   191.        ]\n",
      " [ 288.          260.          247.          237.          310.\n",
      "   308.          277.          282.          273.          260.\n",
      "   220.          214.          197.          191.          195.\n",
      "   198.          195.          181.          187.          174.\n",
      "   176.        ]\n",
      " [ 248.          236.          231.          238.          321.\n",
      "   306.          269.          252.          245.          228.\n",
      "   185.          180.          171.          165.          178.\n",
      "   185.          165.          149.          158.          156.\n",
      "   158.        ]\n",
      " [ 200.          181.          163.          182.          227.\n",
      "   204.          193.          190.          178.          165.\n",
      "   135.          124.          125.          114.          110.\n",
      "   103.           96.           95.1          99.          100.\n",
      "   100.        ]\n",
      " [ 168.          155.          129.          181.          205.\n",
      "   167.          162.          155.          142.          122.\n",
      "   102.           99.2         102.           94.2         102.\n",
      "    97.9          91.7          86.7          85.5          85.5\n",
      "    88.        ]\n",
      " [ 135.          125.          106.          170.          165.\n",
      "   133.          129.          123.          108.           87.6\n",
      "    80.1          81.1          80.1          75.9          72.8\n",
      "    69.1          61.9          66.3          68.2          66.3\n",
      "    69.1       ]\n",
      " [  36.3          29.9          52.          109.           63.6\n",
      "    46.           44.6          35.2          31.5          24.9\n",
      "    27.           27.           25.9          24.4          23.9\n",
      "    20.1          18.5          21.           20.1          20.1\n",
      "    21.4       ]\n",
      " [  20.95774233   20.95774233   20.95774233   20.95774233   20.95774233\n",
      "    20.95774233   20.95774233   20.95774233   20.95774233   20.95774233\n",
      "    20.95774233   20.95774233   20.95774233   20.95774233   20.95774233\n",
      "    20.95774233   20.95774233   20.95774233   20.95774233   20.95774233\n",
      "    20.95774233]\n",
      " [ 732.38325524  732.38325524  732.38325524  732.38325524  732.38325524\n",
      "   732.38325524  732.38325524  732.38325524  732.38325524  732.38325524\n",
      "   732.38325524  732.38325524  732.38325524  732.38325524  732.38325524\n",
      "   732.38325524  732.38325524  732.38325524  732.38325524  732.38325524\n",
      "   732.38325524]\n",
      " [ 171.11155352  171.11155352  171.11155352  171.11155352  171.11155352\n",
      "   171.11155352  171.11155352  171.11155352  171.11155352  171.11155352\n",
      "   171.11155352  171.11155352  171.11155352  171.11155352  171.11155352\n",
      "   171.11155352  171.11155352  171.11155352  171.11155352  171.11155352\n",
      "   171.11155352]\n",
      " [ 159.6648647   159.6648647   159.6648647   159.6648647   159.6648647\n",
      "   159.6648647   159.6648647   159.6648647   159.6648647   159.6648647\n",
      "   159.6648647   159.6648647   159.6648647   159.6648647   159.6648647\n",
      "   159.6648647   159.6648647   159.6648647   159.6648647   159.6648647\n",
      "   159.6648647 ]\n",
      " [  62.17256678   62.17256678   62.17256678   62.17256678   62.17256678\n",
      "    62.17256678   62.17256678   62.17256678   62.17256678   62.17256678\n",
      "    62.17256678   62.17256678   62.17256678   62.17256678   62.17256678\n",
      "    62.17256678   62.17256678   62.17256678   62.17256678   62.17256678\n",
      "    62.17256678]\n",
      " [  47.17658458   47.17658458   47.17658458   47.17658458   47.17658458\n",
      "    47.17658458   47.17658458   47.17658458   47.17658458   47.17658458\n",
      "    47.17658458   47.17658458   47.17658458   47.17658458   47.17658458\n",
      "    47.17658458   47.17658458   47.17658458   47.17658458   47.17658458\n",
      "    47.17658458]\n",
      " [  27.01952079   27.01952079   27.01952079   27.01952079   27.01952079\n",
      "    27.01952079   27.01952079   27.01952079   27.01952079   27.01952079\n",
      "    27.01952079   27.01952079   27.01952079   27.01952079   27.01952079\n",
      "    27.01952079   27.01952079   27.01952079   27.01952079   27.01952079\n",
      "    27.01952079]\n",
      " [  19.73095558   19.73095558   19.73095558   19.73095558   19.73095558\n",
      "    19.73095558   19.73095558   19.73095558   19.73095558   19.73095558\n",
      "    19.73095558   19.73095558   19.73095558   19.73095558   19.73095558\n",
      "    19.73095558   19.73095558   19.73095558   19.73095558   19.73095558\n",
      "    19.73095558]\n",
      " [ 112.2873183   112.2873183   112.2873183   112.2873183   112.2873183\n",
      "   112.2873183   112.2873183   112.2873183   112.2873183   112.2873183\n",
      "   112.2873183   112.2873183   112.2873183   112.2873183   112.2873183\n",
      "   112.2873183   112.2873183   112.2873183   112.2873183   112.2873183\n",
      "   112.2873183 ]\n",
      " [  78.91576623   78.91576623   78.91576623   78.91576623   78.91576623\n",
      "    78.91576623   78.91576623   78.91576623   78.91576623   78.91576623\n",
      "    78.91576623   78.91576623   78.91576623   78.91576623   78.91576623\n",
      "    78.91576623   78.91576623   78.91576623   78.91576623   78.91576623\n",
      "    78.91576623]\n",
      " [  69.71982834   69.71982834   69.71982834   69.71982834   69.71982834\n",
      "    69.71982834   69.71982834   69.71982834   69.71982834   69.71982834\n",
      "    69.71982834   69.71982834   69.71982834   69.71982834   69.71982834\n",
      "    69.71982834   69.71982834   69.71982834   69.71982834   69.71982834\n",
      "    69.71982834]\n",
      " [  49.63537213   49.63537213   49.63537213   49.63537213   49.63537213\n",
      "    49.63537213   49.63537213   49.63537213   49.63537213   49.63537213\n",
      "    49.63537213   49.63537213   49.63537213   49.63537213   49.63537213\n",
      "    49.63537213   49.63537213   49.63537213   49.63537213   49.63537213\n",
      "    49.63537213]\n",
      " [  37.71062816   37.71062816   37.71062816   37.71062816   37.71062816\n",
      "    37.71062816   37.71062816   37.71062816   37.71062816   37.71062816\n",
      "    37.71062816   37.71062816   37.71062816   37.71062816   37.71062816\n",
      "    37.71062816   37.71062816   37.71062816   37.71062816   37.71062816\n",
      "    37.71062816]\n",
      " [  37.23651324   37.23651324   37.23651324   37.23651324   37.23651324\n",
      "    37.23651324   37.23651324   37.23651324   37.23651324   37.23651324\n",
      "    37.23651324   37.23651324   37.23651324   37.23651324   37.23651324\n",
      "    37.23651324   37.23651324   37.23651324   37.23651324   37.23651324\n",
      "    37.23651324]\n",
      " [  33.88651226   33.88651226   33.88651226   33.88651226   33.88651226\n",
      "    33.88651226   33.88651226   33.88651226   33.88651226   33.88651226\n",
      "    33.88651226   33.88651226   33.88651226   33.88651226   33.88651226\n",
      "    33.88651226   33.88651226   33.88651226   33.88651226   33.88651226\n",
      "    33.88651226]\n",
      " [  25.67607254   25.67607254   25.67607254   25.67607254   25.67607254\n",
      "    25.67607254   25.67607254   25.67607254   25.67607254   25.67607254\n",
      "    25.67607254   25.67607254   25.67607254   25.67607254   25.67607254\n",
      "    25.67607254   25.67607254   25.67607254   25.67607254   25.67607254\n",
      "    25.67607254]\n",
      " [  41.12310799   41.12310799   41.12310799   41.12310799   41.12310799\n",
      "    41.12310799   41.12310799   41.12310799   41.12310799   41.12310799\n",
      "    41.12310799   41.12310799   41.12310799   41.12310799   41.12310799\n",
      "    41.12310799   41.12310799   41.12310799   41.12310799   41.12310799\n",
      "    41.12310799]\n",
      " [  36.89404551   36.89404551   36.89404551   36.89404551   36.89404551\n",
      "    36.89404551   36.89404551   36.89404551   36.89404551   36.89404551\n",
      "    36.89404551   36.89404551   36.89404551   36.89404551   36.89404551\n",
      "    36.89404551   36.89404551   36.89404551   36.89404551   36.89404551\n",
      "    36.89404551]\n",
      " [ 251.04848534  251.04848534  251.04848534  251.04848534  251.04848534\n",
      "   251.04848534  251.04848534  251.04848534  251.04848534  251.04848534\n",
      "   251.04848534  251.04848534  251.04848534  251.04848534  251.04848534\n",
      "   251.04848534  251.04848534  251.04848534  251.04848534  251.04848534\n",
      "   251.04848534]\n",
      " [ 236.36415386  236.36415386  236.36415386  236.36415386  236.36415386\n",
      "   236.36415386  236.36415386  236.36415386  236.36415386  236.36415386\n",
      "   236.36415386  236.36415386  236.36415386  236.36415386  236.36415386\n",
      "   236.36415386  236.36415386  236.36415386  236.36415386  236.36415386\n",
      "   236.36415386]]\n"
     ]
    }
   ],
   "source": [
    "flagInit = 0\n",
    "meanTr=   mean_X_trainD  \n",
    "stdTr = stdTrtrue \n",
    "if flagInit == 0: \n",
    "    X_train_InitD = mask_trainD * X_train_obsD + (1. - mask_trainD) * (np.zeros(X_train_missingD.shape) + meanTr)\n",
    "    X_val_InitD = mask_valD * X_val_obsD + (1. - mask_valD) * (np.zeros(X_val_missingD.shape) + meanTr)\n",
    "    X_test_InitD  = mask_testD * X_test_obsD + (1. - mask_testD) * (np.zeros(X_test_missingD.shape) + meanTr)    \n",
    "print(X_train_InitD[0,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f105b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_InitD = ( X_train_InitD - meanTr ) / stdTr\n",
    "x_val_InitD = ( X_val_InitD - meanTr ) / stdTr\n",
    "x_test_InitD = ( X_test_InitD - meanTr ) / stdTr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6d09b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f8dda0c2b50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x_train_missingD[0,:,:])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(x_trainD[0,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49902bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d6592a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/home/VM-Nicolas-Lafon/R/x86_64-pc-linux-gnu-library/4.1’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/POT_1.1-7.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 1028906 bytes (1004 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 1004 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/Rtmpp6m0QV/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rpy2.rinterface_lib.sexp.NULLType object at 0x7f88901bfbc0> [RTYPES.NILSXP]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "base = importr('base')\n",
    "utils = importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "utils.install_packages('POT') #installing POT package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ac780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thresholdmodeling import thresh_modeling as t#importing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c25b55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220.0\n",
      "Estimator: MLE \n",
      " Deviance: 26419.25 \n",
      "      AIC: 26423.25 \n",
      "\n",
      "Varying Threshold: FALSE \n",
      "\n",
      "  Threshold Call: 2220L \n",
      "    Number Above: 1806 \n",
      "Proportion Above: 0.099 \n",
      "\n",
      "Estimates\n",
      "    scale      shape  \n",
      "519.76173    0.06087  \n",
      "\n",
      "Standard Error Type: observed \n",
      "\n",
      "Standard Errors\n",
      "   scale     shape  \n",
      "18.07857   0.02565  \n",
      "\n",
      "Asymptotic Variance Covariance\n",
      "       scale       shape     \n",
      "scale  326.834654   -0.323444\n",
      "shape   -0.323444    0.000658\n",
      "\n",
      "Optimization Information\n",
      "  Convergence: successful \n",
      "  Function Evaluations: 47 \n",
      "  Gradient Evaluations: 21 \n",
      "\n",
      "\n",
      "0.06087419450403571\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "x=dataset[:,i]\n",
    "s = seuil_10[i]\n",
    "print(s)\n",
    "ksi=t.gpdfit(x,2220,'mle')\n",
    "print(ksi[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc836040",
   "metadata": {},
   "source": [
    "<table>\n",
    "<caption style=\"caption-side:bottom\">Paramètre de forme par station</caption>\n",
    "<tr>\n",
    "<th>Station</th>\n",
    "<th>1</th>\n",
    "<th>2</th>\n",
    "<th>3</th>\n",
    "<th>4</th>\n",
    "<th>5</th>\n",
    "<th>6</th>\n",
    "<th>7</th>\n",
    "<th>8</th>\n",
    "<th>9</th>\n",
    "<th>10</th>\n",
    "<th>11</th>\n",
    "<th>12</th>\n",
    "<th>13</th>\n",
    "<th>14</th>\n",
    "<th>15</th>\n",
    "<th>16</th>\n",
    "<th>17</th>\n",
    "<th>18</th>\n",
    "<th>19</th>\n",
    "<th>20</th>\n",
    "<th>21</th>\n",
    "<th>22</th>\n",
    "<th>23</th>\n",
    "<th>24</th>\n",
    "<th>25</th>\n",
    "<th>26</th>\n",
    "<th>27</th>\n",
    "<th>28</th>\n",
    "<th>29</th>\n",
    "<th>30</th>\n",
    "<th>31</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Shape</th>\n",
    "<th>0.061</th>\n",
    "<th>0.052</th>\n",
    "<th>0.083</th>\n",
    "<th>0.073</th>\n",
    "<th>0.062</th>\n",
    "<th>0.092</th>\n",
    "<th>0.086</th>\n",
    "<th>0.055</th>\n",
    "<th>0.052</th>\n",
    "<th>0.050</th>\n",
    "<th>0.20</th>\n",
    "<th>0.15</th>\n",
    "<th>0.15</th>\n",
    "<th>0.18</th>\n",
    "<th>0.22</th>\n",
    "<th>0.21</th>\n",
    "<th>0.24</th>\n",
    "<th>0.28</th>\n",
    "<th>0.29</th>\n",
    "<th>0.34</th>\n",
    "<th>0.23</th>\n",
    "<th>0.21</th>\n",
    "<th>0.14</th>\n",
    "<th>0.14</th>\n",
    "<th>0.25</th>\n",
    "<th>0.26</th>\n",
    "<th>0.28</th>\n",
    "<th>0.22</th>\n",
    "<th>0.24</th>\n",
    "<th>0.18</th>\n",
    "<th>0.18</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Standard Error</th>\n",
    "<th>0.035</th>\n",
    "<th>0.027</th>\n",
    "<th>0.028</th>\n",
    "<th>0.027</th>\n",
    "<th>0.026</th>\n",
    "<th>0.027</th>\n",
    "<th>0.026</th>\n",
    "<th>0.027</th>\n",
    "<th>0.026</th>\n",
    "<th>0.026</th>\n",
    "<th>0.028</th>\n",
    "<th>0.024</th>\n",
    "<th>0.027</th>\n",
    "<th>0.027</th>\n",
    "<th>0.027</th>\n",
    "<th>0.028</th>\n",
    "<th>0.030</th>\n",
    "<th>0.032</th>\n",
    "<th>0.030</th>\n",
    "<th>0.032</th>\n",
    "<th>0.028</th>\n",
    "<th>0.028</th>\n",
    "<th>0.027</th>\n",
    "<th>0.026</th>\n",
    "<th>0.032</th>\n",
    "<th>0.031</th>\n",
    "<th>0.031</th>\n",
    "<th>0.028</th>\n",
    "<th>0.028</th>\n",
    "<th>0.027</th>\n",
    "<th>0.027</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342bf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210421ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4dvarnet",
   "language": "python",
   "name": "4dvarnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
