{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237d7538",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Updated_Solver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-86f3927fe55a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# specific torch module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#import dinAE_solver_torch as dinAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mUpdated_Solver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mNN_4DVar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#import torch4DVarNN_solver as NN_4DVar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Updated_Solver'"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "#import os\n",
    "#import tensorflow.keras as keras\n",
    "import xarray as xr\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.feature_extraction import image\n",
    "from netCDF4 import Dataset\n",
    "import datetime\n",
    "\n",
    "# specific torch module \n",
    "#import dinAE_solver_torch as dinAE\n",
    "import torch_4DVarNN_dinAE_Copy1 as NN_4DVar\n",
    "#import torch4DVarNN_solver as NN_4DVar\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "parser = argparse.ArgumentParser()\n",
    "flagProcess    = [0,1,2,3,4]#Sequence fo processes to be run\n",
    "    \n",
    "flagRandomSeed = 0\n",
    "flagSaveModel  = 1\n",
    "     \n",
    "batch_size  = 96#4#4#8#12#8#256#8\n",
    "\n",
    "dirSAVE     = './ResDanube4DVar/'\n",
    "suffix_exp='exp2'\n",
    "genFilename = 'Debit_v11'\n",
    "  \n",
    "flagAEType = 2 # 0: L96 model, 1-2: GENN\n",
    "DimAE      = 50#50#10#50\n",
    "    \n",
    "UsePriodicBoundary = True # use a periodic boundary for all conv operators in the gradient model (see torch_4DVarNN_dinAE)\n",
    "InterpFlag         = False\n",
    "\n",
    "NbDays          = 18244\n",
    "\n",
    "time_step  = 1\n",
    "DT = 21\n",
    "sigNoise   = np.sqrt(2)\n",
    "rateMissingData = 0.5#0.9\n",
    "width_med_filt_spatial = 5\n",
    "width_med_filt_temp = 1\n",
    "###############################################################\n",
    "## data extraction\n",
    "ncfile = Dataset('Dataset_danube.nc',\"r\")\n",
    "L=[]\n",
    "for i in range(31):\n",
    "    L.append(ncfile['S'+str(i+1)][:].reshape(18244,1))\n",
    "        \n",
    "dataset = np.concatenate((L[0],L[1],L[2],L[3],L[4],L[5],L[6],L[7],L[8],L[9],L[10],L[11],L[12],L[13],L[14],L[15],L[16],L[17],L[18],L[19],L[20],L[21],L[22],L[23],L[24],L[25],L[26],L[27],L[28],L[29],L[30]),axis=1)\n",
    "\n",
    "# Definiton of training, validation and test dataset    \n",
    "i=0\n",
    "Indtrain=[]\n",
    "Indval=[]\n",
    "Indtest=[]\n",
    "while (i+1)*395<(NbDays-1):\n",
    "    x=395*i\n",
    "    Indtrain.append([x,(x+305)])\n",
    "    Indval.append([(x+319),(x+350)])\n",
    "    Indtest.append([x+364,x+395])\n",
    "    i+=1\n",
    "    \n",
    "\n",
    "#Se restreindre à l'été car pas de pluie??\n",
    "day0=datetime.date(1960,1,1)\n",
    "dayend=datetime.date(2009,12,12)\n",
    "\n",
    "\n",
    "#Trouver une valeur de seuil pour étudier le coût KL au-dessus du seuil : on se place dans flagTypeProcess 3 avec la station 4 masquée\n",
    "\n",
    "D=dataset[Indtrain[0][0]:Indtrain[0][1],3]\n",
    "for k in Indtrain[1::]:\n",
    "    D=np.concatenate((D,dataset[k[0]:k[1],3]),axis=0)\n",
    "r=0.1 #fraction supérieure \n",
    "D.sort()\n",
    "seuil=D[int((1-r)*len(D))]\n",
    "\n",
    "\n",
    "    ####################################################\n",
    "## Generation of training  validationand test dataset\n",
    "## Extraction of time series of dT time steps\n",
    "#NbTraining = 6000#2000\n",
    "#NbTest     = 256#256#500\n",
    "#NbVal = ?\n",
    "    \n",
    "dataTrainingNoNaND = image.extract_patches_2d(dataset[Indtrain[0][0]:Indtrain[0][1],:],(DT,31)) \n",
    "for k in Indtrain[1::]:\n",
    "    d= image.extract_patches_2d(dataset[k[0]:k[1],:],(DT,31))\n",
    "    dataTrainingNoNaND=np.concatenate((dataTrainingNoNaND,d),axis=0)\n",
    "        \n",
    "    \n",
    "dataValNoNaND = image.extract_patches_2d(dataset[Indval[0][0]:Indval[0][1],:],(DT,31))    \n",
    "for k in Indval[1::]:\n",
    "    d= image.extract_patches_2d(dataset[k[0]:k[1],:],(DT,31))\n",
    "    dataValNoNaND=np.concatenate((dataValNoNaND,d),axis=0)\n",
    "print(dataValNoNaND.shape )  \n",
    "    \n",
    "dataTestNoNaND = image.extract_patches_2d(dataset[Indtest[0][0]:Indtest[0][1],:],(DT,31))\n",
    "for k in Indtest[1::]:\n",
    "    d= image.extract_patches_2d(dataset[k[0]:k[1],:],(DT,31))\n",
    "    dataTestNoNaND=np.concatenate((dataTestNoNaND,d),axis=0)\n",
    "print(dataTestNoNaND.shape ) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    dataTrainingD    = np.zeros((dataTrainingNoNaND.shape))\n",
    "    dataTrainingD[:] = float('nan')\n",
    "            \n",
    "    dataValD    = np.zeros((dataValNoNaND.shape))\n",
    "    dataValD[:] = float('nan')\n",
    "            \n",
    "    dataTestD        = np.zeros((dataTestNoNaND.shape))\n",
    "    dataTestD[:]     = float('nan')\n",
    "    \n",
    "    dataTrainingD[:,:(int(DT/2+1)),:] = dataTrainingNoNaND[:,:(int(DT/2+1)),:]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4dvarnet",
   "language": "python",
   "name": "4dvarnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
